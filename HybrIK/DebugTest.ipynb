{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "290c60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8882a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:SHA could not be resolved, git returned: b''\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "os.getcwd()\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from hybrik.utils.metrics import calc_coord_accuracy\n",
    "from hybrik.utils.config import update_config\n",
    "from hybrik.models import builder\n",
    "from hybrik.datasets import MixDataset, PW3D\n",
    "import torch.utils.data\n",
    "\n",
    "from pytorch3d.transforms import quaternion_to_axis_angle, quaternion_to_matrix, matrix_to_quaternion, \\\n",
    "    axis_angle_to_quaternion, rotation_6d_to_matrix\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from deeppose.collections.common.metrics.pa_mpjpe import PA_MPJPE\n",
    "from deeppose.collections.common.metrics.mpjpe import MPJPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8b6985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f358b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_device(d, device):\n",
    "    d_device = {}\n",
    "    for k, v in d.items():\n",
    "        d_device[k] = v.to(device)\n",
    "    return d_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1029dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preset_model(cfg, detach=False, device=None):\n",
    "    model = builder.build_sppe(cfg.MODEL)\n",
    "\n",
    "    if cfg.MODEL.PRETRAINED:\n",
    "        print(f'Loading model from {cfg.MODEL.PRETRAINED}...')\n",
    "        model.load_state_dict(torch.load(cfg.MODEL.PRETRAINED))\n",
    "    elif cfg.MODEL.TRY_LOAD:\n",
    "        print(f'Loading model from {cfg.MODEL.TRY_LOAD}...')\n",
    "        pretrained_state = torch.load(cfg.MODEL.TRY_LOAD)\n",
    "        model_state = model.state_dict()\n",
    "        pretrained_state = {k: v for k, v in pretrained_state.items()\n",
    "                            if k in model_state and v.size() == model_state[k].size()}\n",
    "\n",
    "        model_state.update(pretrained_state)\n",
    "        model.load_state_dict(model_state)\n",
    "    else:\n",
    "        print('Create new model')\n",
    "        print('=> init weights')\n",
    "        model._initialize()\n",
    "        \n",
    "    if detach:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    if device is not None:\n",
    "        model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c8ab2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASET': {'DATASET': 'mix_smpl',\n",
       "  'SET_LIST': [{'ROOT': './data/h36m/',\n",
       "    'TEST_SET': 'Sample_20_test_Human36M_smpl',\n",
       "    'TRAIN_SET': 'Sample_5_train_Human36M_smpl_leaf_twist'},\n",
       "   {'ROOT': './data/coco/', 'TRAIN_SET': 'train2017'},\n",
       "   {'ROOT': './data/3dhp/', 'TRAIN_SET': 'train_v2'}],\n",
       "  'PROTOCOL': 2,\n",
       "  'FLIP': True,\n",
       "  'ROT_FACTOR': 30,\n",
       "  'SCALE_FACTOR': 0.3,\n",
       "  'NUM_JOINTS_HALF_BODY': 8,\n",
       "  'PROB_HALF_BODY': -1,\n",
       "  'COLOR_FACTOR': 0.2,\n",
       "  'OCCLUSION': True},\n",
       " 'MODEL': {'TYPE': 'DeepposeTransformerSMPL24',\n",
       "  'PRETRAINED': '',\n",
       "  'TRY_LOAD': '',\n",
       "  'IMAGE_SIZE': [256, 256],\n",
       "  'HEATMAP_SIZE': [64, 64],\n",
       "  'NUM_JOINTS': 24,\n",
       "  'NUM_DECONV_FILTERS': [256, 256, 256],\n",
       "  'NUM_LAYERS': 34,\n",
       "  'EXTRA': {'SIGMA': 2,\n",
       "   'BACKBONE': 'resnet',\n",
       "   'CROP': 'padding',\n",
       "   'AUGMENT': 'none',\n",
       "   'PRESET': 'simple_smpl_3d',\n",
       "   'DEPTH_DIM': 64},\n",
       "  'POST': {'NORM_TYPE': 'softmax'},\n",
       "  'PROTORES': {'PATH': 'model_files/h36m/epoch=471-step=214759-fmn.ckpt'},\n",
       "  'TRANSFORMER': {'NUM_BLOCKS': 2,\n",
       "   'NUM_LAYERS': 3,\n",
       "   'LAYER_WIDTH': 512,\n",
       "   'DROPOUT': 0.1}},\n",
       " 'LOSS': {'TYPE': 'L1LossDimSMPL',\n",
       "  'ELEMENTS': {'BETA_WEIGHT': 1,\n",
       "   'BETA_REG_WEIGHT': 0,\n",
       "   'PHI_REG_WEIGHT': 0.0001,\n",
       "   'LEAF_REG_WEIGHT': 0,\n",
       "   'TWIST_WEIGHT': 0.01,\n",
       "   'THETA_WEIGHT': 0.01,\n",
       "   'UVD24_WEIGHT': 1,\n",
       "   'XYZ24_WEIGHT': 0,\n",
       "   'XYZ_SMPL24_WEIGHT': 0,\n",
       "   'XYZ_SMPL17_WEIGHT': 0,\n",
       "   'VERTICE_WEIGHT': 0}},\n",
       " 'TEST': {'HEATMAP2COORD': 'coord'},\n",
       " 'TRAIN': {'WORLD_SIZE': 1,\n",
       "  'BATCH_SIZE': 256,\n",
       "  'BEGIN_EPOCH': 0,\n",
       "  'END_EPOCH': 200,\n",
       "  'OPTIMIZER': 'adam',\n",
       "  'SCHEDULER': {'TYPE': 'InverseSquareRoot',\n",
       "   'WARMUP_UPDATES': 4000,\n",
       "   'WARMUP_END_LR': 0.0005},\n",
       "  'LR': 0.0005,\n",
       "  'DPG_MILESTONE': 140,\n",
       "  'DPG_STEP': [160, 190]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = 'configs/deeppose_transformer_smpl24.yaml'\n",
    "# cfg = 'configs/256x192_adam_lr1e-3-res34_smpl_24_3d_base_2x_mix.yaml'\n",
    "# configs/256x192_adam_lr1e-3-res34_smpl_24_3d_base_2x_mix.yaml\n",
    "\n",
    "cfg = update_config(cfg)\n",
    "\n",
    "hm_shape = cfg.MODEL.get('HEATMAP_SIZE')\n",
    "depth_dim = cfg.MODEL.EXTRA.get('DEPTH_DIM')\n",
    "hm_shape = (hm_shape[1], hm_shape[0], depth_dim)\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52bd73ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=6.19s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MixDataset(cfg=cfg, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd1b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=256, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/hydra/utils.py:32: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if OmegaConf.is_none(config):\n",
      "/opt/conda/lib/python3.7/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `MeanSquaredError` was deprecated since v1.3.0 in favor of `torchmetrics.regression.mean_squared_error.MeanSquaredError`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from model_files/pretrained/pretrained_res34.pth...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1d06940d894151a03d3adc4a63661d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2439.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 0 #####\n",
      "{'loss_tot': tensor(22.0586, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2817, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0506, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(20.3799, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(13.9476, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(16.1591, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 1 #####\n",
      "{'loss_tot': tensor(31.8322, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2568, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0457, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(30.6427, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(9.3071, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(10.3633, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 2 #####\n",
      "{'loss_tot': tensor(21.7596, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2481, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(20.4576, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(10.5201, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(11.5597, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 3 #####\n",
      "{'loss_tot': tensor(11.7583, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2522, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(10.4578, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(10.4639, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(11.0836, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 4 #####\n",
      "{'loss_tot': tensor(17.0538, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2452, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0432, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(15.8768, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(9.2996, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(9.6725, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 5 #####\n",
      "{'loss_tot': tensor(15.9202, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2153, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(14.9513, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(7.5194, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(7.5390, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 6 #####\n",
      "{'loss_tot': tensor(11.9882, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2112, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(11.1614, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(6.1386, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(6.0830, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 7 #####\n",
      "{'loss_tot': tensor(8.8062, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2370, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(7.9194, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(6.4799, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(6.5617, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 8 #####\n",
      "{'loss_tot': tensor(11.9009, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2396, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(11.0079, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(6.5140, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(6.5101, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 9 #####\n",
      "{'loss_tot': tensor(11.2952, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2060, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(10.4914, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.9629, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(6.0211, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 10 #####\n",
      "{'loss_tot': tensor(9.5570, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2463, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(8.7336, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.7538, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.9267, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 11 #####\n",
      "{'loss_tot': tensor(7.7587, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2186, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.9888, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.4963, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.5294, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 12 #####\n",
      "{'loss_tot': tensor(8.9880, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1952, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0347, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(8.2576, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.3373, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.5652, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 13 #####\n",
      "{'loss_tot': tensor(9.7726, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2598, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(8.9582, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.5293, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.6578, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 14 #####\n",
      "{'loss_tot': tensor(8.9548, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2351, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(8.1912, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.2689, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.4239, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 15 #####\n",
      "{'loss_tot': tensor(7.5876, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2420, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.8252, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1893, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3183, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 16 #####\n",
      "{'loss_tot': tensor(7.4799, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1857, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0268, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.7812, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1176, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.4265, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 17 #####\n",
      "{'loss_tot': tensor(8.3812, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2196, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(7.6513, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0893, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3877, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 18 #####\n",
      "{'loss_tot': tensor(8.4094, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2518, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(7.6352, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.2091, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3809, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 19 #####\n",
      "{'loss_tot': tensor(7.3258, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2111, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.5966, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1682, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3310, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 20 #####\n",
      "{'loss_tot': tensor(7.3454, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1931, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.6350, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1617, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.4892, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 21 #####\n",
      "{'loss_tot': tensor(7.6762, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2349, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.9077, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.3229, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.4111, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 22 #####\n",
      "{'loss_tot': tensor(7.7101, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2219, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0376, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.9713, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1551, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1599, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 23 #####\n",
      "{'loss_tot': tensor(7.1855, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2284, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4510, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0495, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1637, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 24 #####\n",
      "{'loss_tot': tensor(7.1428, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1987, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0311, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4241, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1884, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3144, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 25 #####\n",
      "{'loss_tot': tensor(7.3119, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2111, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.5974, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0231, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0640, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 26 #####\n",
      "{'loss_tot': tensor(7.5490, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2233, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.8166, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0795, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3344, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 27 #####\n",
      "{'loss_tot': tensor(7.1075, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2082, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4015, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9682, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.2064, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 28 #####\n",
      "{'loss_tot': tensor(7.1512, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2295, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.3954, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.2524, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.4594, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 29 #####\n",
      "{'loss_tot': tensor(7.3720, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1988, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.6623, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0993, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1986, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 30 #####\n",
      "{'loss_tot': tensor(7.1291, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2549, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.3609, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1222, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3408, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 31 #####\n",
      "{'loss_tot': tensor(7.1186, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2058, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4028, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0900, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3874, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 32 #####\n",
      "{'loss_tot': tensor(7.1197, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1982, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4066, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1400, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3609, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 33 #####\n",
      "{'loss_tot': tensor(7.1311, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2233, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.3931, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1377, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.2934, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 34 #####\n",
      "{'loss_tot': tensor(6.7187, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1957, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0400, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8221, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8739, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 35 #####\n",
      "{'loss_tot': tensor(7.2707, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2158, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.5371, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1698, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3742, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 36 #####\n",
      "{'loss_tot': tensor(7.0882, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2336, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.3586, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9515, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1703, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 37 #####\n",
      "{'loss_tot': tensor(7.1731, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2324, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4395, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0021, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.2483, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 38 #####\n",
      "{'loss_tot': tensor(7.0136, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2285, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.2824, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0183, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1334, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 39 #####\n",
      "{'loss_tot': tensor(7.1664, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1990, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4516, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.1505, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3913, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 40 #####\n",
      "{'loss_tot': tensor(6.6362, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2605, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8850, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8988, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9759, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 41 #####\n",
      "{'loss_tot': tensor(6.7075, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2039, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0323, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0259, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7695, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8146, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 42 #####\n",
      "{'loss_tot': tensor(7.0732, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2185, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.3683, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8574, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9766, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 43 #####\n",
      "{'loss_tot': tensor(6.9038, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2305, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.1848, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8765, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9690, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 44 #####\n",
      "{'loss_tot': tensor(6.9118, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2257, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.1806, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0483, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0318, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 45 #####\n",
      "{'loss_tot': tensor(6.4002, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2291, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7012, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6907, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6980, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 46 #####\n",
      "{'loss_tot': tensor(6.7885, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1963, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.1121, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7936, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9995, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 47 #####\n",
      "{'loss_tot': tensor(7.1221, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2110, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.4128, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9752, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1773, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 48 #####\n",
      "{'loss_tot': tensor(6.6727, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2060, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9910, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7496, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8710, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 49 #####\n",
      "{'loss_tot': tensor(7.0208, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2601, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.2660, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9388, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0440, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 50 #####\n",
      "{'loss_tot': tensor(6.8753, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2194, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.1602, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9506, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0574, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 51 #####\n",
      "{'loss_tot': tensor(6.9963, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1905, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.3196, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8568, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1299, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 52 #####\n",
      "{'loss_tot': tensor(6.7724, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2218, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0660, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8390, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0672, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 53 #####\n",
      "{'loss_tot': tensor(6.5034, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2176, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8118, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7340, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7898, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 54 #####\n",
      "{'loss_tot': tensor(6.6238, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2373, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8988, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8695, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1044, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 55 #####\n",
      "{'loss_tot': tensor(6.9170, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2441, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.1654, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0675, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.3897, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 56 #####\n",
      "{'loss_tot': tensor(6.5367, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2281, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8290, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7894, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8551, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 57 #####\n",
      "{'loss_tot': tensor(6.4388, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2182, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0306, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7512, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6886, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7403, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 58 #####\n",
      "{'loss_tot': tensor(6.6991, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2358, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9685, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9409, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0988, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 59 #####\n",
      "{'loss_tot': tensor(6.5209, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2329, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8046, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8274, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9220, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 60 #####\n",
      "{'loss_tot': tensor(6.5609, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2275, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8496, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8320, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0503, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 61 #####\n",
      "{'loss_tot': tensor(6.6015, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2335, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8941, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7323, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8828, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 62 #####\n",
      "{'loss_tot': tensor(6.7604, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2009, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0581, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0072, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.2205, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 63 #####\n",
      "{'loss_tot': tensor(6.8305, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2210, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.1046, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0431, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.2051, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 64 #####\n",
      "{'loss_tot': tensor(6.7521, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2643, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9858, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(5.0137, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1738, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 65 #####\n",
      "{'loss_tot': tensor(6.7854, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2130, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0299, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0728, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9898, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1289, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 66 #####\n",
      "{'loss_tot': tensor(6.6378, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1881, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9628, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8645, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0664, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 67 #####\n",
      "{'loss_tot': tensor(6.3738, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2213, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6682, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8382, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9464, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 68 #####\n",
      "{'loss_tot': tensor(6.5910, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2331, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8720, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8527, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0584, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 69 #####\n",
      "{'loss_tot': tensor(6.6272, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2286, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9054, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9263, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1384, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 70 #####\n",
      "{'loss_tot': tensor(6.5458, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2419, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8245, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7867, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9841, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 71 #####\n",
      "{'loss_tot': tensor(6.4203, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2293, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7149, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7557, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0054, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 72 #####\n",
      "{'loss_tot': tensor(6.4336, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2236, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7423, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6718, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7562, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 73 #####\n",
      "{'loss_tot': tensor(6.5443, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1732, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8835, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8712, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0940, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 74 #####\n",
      "{'loss_tot': tensor(6.3350, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2131, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6606, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6080, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7813, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 75 #####\n",
      "{'loss_tot': tensor(6.5618, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2324, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8527, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7605, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8003, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 76 #####\n",
      "{'loss_tot': tensor(6.6436, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1896, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9689, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8453, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9748, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 77 #####\n",
      "{'loss_tot': tensor(6.5901, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2155, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9003, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7377, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9071, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 78 #####\n",
      "{'loss_tot': tensor(6.6909, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2397, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9823, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6828, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9030, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 79 #####\n",
      "{'loss_tot': tensor(6.1465, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2063, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4754, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6419, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7015, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 80 #####\n",
      "{'loss_tot': tensor(6.4984, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2125, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8123, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7307, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8824, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 81 #####\n",
      "{'loss_tot': tensor(6.4643, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1669, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0240, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8379, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5915, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6577, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 82 #####\n",
      "{'loss_tot': tensor(6.6218, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2288, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0314, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9236, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6882, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9231, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 83 #####\n",
      "{'loss_tot': tensor(6.6981, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2155, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9911, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1597, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 84 #####\n",
      "{'loss_tot': tensor(6.6043, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2248, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8957, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8322, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9344, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 85 #####\n",
      "{'loss_tot': tensor(6.5535, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2551, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8129, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8482, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9676, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 86 #####\n",
      "{'loss_tot': tensor(6.6909, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2389, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9780, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7342, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0265, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 87 #####\n",
      "{'loss_tot': tensor(6.4489, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2324, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7467, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6923, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8184, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 88 #####\n",
      "{'loss_tot': tensor(6.2936, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1831, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6420, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6800, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8147, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 89 #####\n",
      "{'loss_tot': tensor(6.6005, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1668, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9789, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5431, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6716, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 90 #####\n",
      "{'loss_tot': tensor(6.5478, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2078, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8600, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7951, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0096, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 91 #####\n",
      "{'loss_tot': tensor(6.7884, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2267, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0732, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8798, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.1326, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 92 #####\n",
      "{'loss_tot': tensor(6.5402, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2031, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8620, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7461, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9456, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 93 #####\n",
      "{'loss_tot': tensor(6.5051, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2190, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8205, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6499, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8804, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 94 #####\n",
      "{'loss_tot': tensor(6.3513, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1877, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0265, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6939, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6927, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6479, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 95 #####\n",
      "{'loss_tot': tensor(6.6417, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2319, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9301, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7908, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8985, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 96 #####\n",
      "{'loss_tot': tensor(6.6796, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1890, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0121, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7801, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8062, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 97 #####\n",
      "{'loss_tot': tensor(6.1788, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2321, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4907, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5541, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5958, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 98 #####\n",
      "{'loss_tot': tensor(6.4322, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2438, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7124, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7540, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9409, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 99 #####\n",
      "{'loss_tot': tensor(6.4296, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2507, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7126, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6573, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7663, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 100 #####\n",
      "{'loss_tot': tensor(6.2529, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1977, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5984, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5622, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6892, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 101 #####\n",
      "{'loss_tot': tensor(6.6824, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2233, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0340, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.9681, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9050, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0153, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 102 #####\n",
      "{'loss_tot': tensor(6.2011, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2033, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5408, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5650, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5175, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 103 #####\n",
      "{'loss_tot': tensor(6.6250, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2626, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8918, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7008, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7475, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 104 #####\n",
      "{'loss_tot': tensor(6.9919, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2195, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.2808, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9105, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0361, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 105 #####\n",
      "{'loss_tot': tensor(6.4561, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2344, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7533, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6782, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8272, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 106 #####\n",
      "{'loss_tot': tensor(6.5765, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2829, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8101, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8291, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9312, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 107 #####\n",
      "{'loss_tot': tensor(6.3613, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2462, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0360, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6452, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6922, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7812, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 108 #####\n",
      "{'loss_tot': tensor(6.2425, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2612, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5005, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8032, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8918, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 109 #####\n",
      "{'loss_tot': tensor(6.2284, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2362, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5254, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6621, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7454, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 110 #####\n",
      "{'loss_tot': tensor(6.1101, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1947, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4547, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6015, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6684, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 111 #####\n",
      "{'loss_tot': tensor(6.5904, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2358, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8639, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.9024, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(5.0510, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 112 #####\n",
      "{'loss_tot': tensor(6.4401, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1990, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7578, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8280, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9181, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 113 #####\n",
      "{'loss_tot': tensor(6.2350, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2281, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5453, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6033, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 114 #####\n",
      "{'loss_tot': tensor(6.4760, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2220, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7757, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7785, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9488, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 115 #####\n",
      "{'loss_tot': tensor(6.3823, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2163, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6986, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6694, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7433, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 116 #####\n",
      "{'loss_tot': tensor(6.5195, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1887, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8472, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.8312, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.9929, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 117 #####\n",
      "{'loss_tot': tensor(6.0427, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2226, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.3609, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5869, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6247, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 118 #####\n",
      "{'loss_tot': tensor(6.4089, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2019, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7323, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7411, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6904, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 119 #####\n",
      "{'loss_tot': tensor(6.5514, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2085, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0359, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8637, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7855, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7977, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 120 #####\n",
      "{'loss_tot': tensor(6.3739, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2202, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6797, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7343, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6781, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 121 #####\n",
      "{'loss_tot': tensor(6.3412, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2477, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6233, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6953, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8717, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 122 #####\n",
      "{'loss_tot': tensor(6.4488, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2087, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7642, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7538, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7609, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 123 #####\n",
      "{'loss_tot': tensor(6.4810, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2114, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7954, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7362, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8517, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 124 #####\n",
      "{'loss_tot': tensor(6.4009, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2116, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7193, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6950, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8456, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 125 #####\n",
      "{'loss_tot': tensor(6.3739, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1747, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7412, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5750, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6671, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 126 #####\n",
      "{'loss_tot': tensor(6.0539, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2281, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.3794, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4573, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5271, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 127 #####\n",
      "{'loss_tot': tensor(6.2860, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2134, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5982, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7388, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8024, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 128 #####\n",
      "{'loss_tot': tensor(6.7360, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2183, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(6.0478, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6935, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.8048, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 129 #####\n",
      "{'loss_tot': tensor(6.3462, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2560, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0386, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6210, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6864, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6328, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 130 #####\n",
      "{'loss_tot': tensor(6.2073, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2016, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0388, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5407, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6431, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6026, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 131 #####\n",
      "{'loss_tot': tensor(6.1745, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2423, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4772, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5447, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5663, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 132 #####\n",
      "{'loss_tot': tensor(6.5278, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2303, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8231, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.7385, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7773, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 133 #####\n",
      "{'loss_tot': tensor(6.3574, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1952, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0327, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6940, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6772, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7302, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 134 #####\n",
      "{'loss_tot': tensor(6.4013, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2327, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7014, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6671, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7618, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 135 #####\n",
      "{'loss_tot': tensor(6.3196, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2402, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0373, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6198, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5899, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6278, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 136 #####\n",
      "{'loss_tot': tensor(6.2055, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2172, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5201, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6762, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5862, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 137 #####\n",
      "{'loss_tot': tensor(6.2746, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2328, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5842, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5697, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5649, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 138 #####\n",
      "{'loss_tot': tensor(6.2366, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1706, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0297, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6183, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4726, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.3902, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 139 #####\n",
      "{'loss_tot': tensor(5.8917, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2343, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0392, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2134, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4340, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.2780, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 140 #####\n",
      "{'loss_tot': tensor(6.3567, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2407, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.6608, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5459, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.3971, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 141 #####\n",
      "{'loss_tot': tensor(6.4615, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2176, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0331, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7943, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4918, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.3051, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 142 #####\n",
      "{'loss_tot': tensor(6.5411, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2349, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8414, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6427, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.4960, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 143 #####\n",
      "{'loss_tot': tensor(5.9148, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1883, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2804, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4570, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.4010, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 144 #####\n",
      "{'loss_tot': tensor(6.2708, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2212, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5949, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5424, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5721, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 145 #####\n",
      "{'loss_tot': tensor(6.5100, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2344, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8146, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6049, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6274, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 146 #####\n",
      "{'loss_tot': tensor(6.0773, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2404, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4046, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3181, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.3785, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 147 #####\n",
      "{'loss_tot': tensor(5.9640, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2154, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2934, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5473, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.5194, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 148 #####\n",
      "{'loss_tot': tensor(6.1721, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1979, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5083, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6543, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.6127, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 149 #####\n",
      "{'loss_tot': tensor(6.1558, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2336, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4607, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.6102, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.7195, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 150 #####\n",
      "{'loss_tot': tensor(6.5042, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1995, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.8499, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.5424, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.4673, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 151 #####\n",
      "{'loss_tot': tensor(5.9858, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2610, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2777, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4650, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.4160, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 152 #####\n",
      "{'loss_tot': tensor(6.4008, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2200, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0356, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7369, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4341, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.2759, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 153 #####\n",
      "{'loss_tot': tensor(5.7534, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2251, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0348, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.0973, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3042, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0831, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 154 #####\n",
      "{'loss_tot': tensor(6.2359, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2213, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5750, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3914, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.1837, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 155 #####\n",
      "{'loss_tot': tensor(6.1888, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2070, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.5333, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4791, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.2539, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 156 #####\n",
      "{'loss_tot': tensor(6.0329, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1902, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4028, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3935, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.1360, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 157 #####\n",
      "{'loss_tot': tensor(6.3700, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1946, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.7429, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3201, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9710, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 158 #####\n",
      "{'loss_tot': tensor(6.1229, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2234, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4575, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4148, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.3209, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 159 #####\n",
      "{'loss_tot': tensor(5.8207, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2062, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1749, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3914, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.3203, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 160 #####\n",
      "{'loss_tot': tensor(5.9188, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2337, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0325, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2366, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4803, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.2621, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 161 #####\n",
      "{'loss_tot': tensor(6.0104, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2082, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0332, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.3646, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3707, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0946, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 162 #####\n",
      "{'loss_tot': tensor(5.7428, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2421, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.0782, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2194, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9322, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 163 #####\n",
      "{'loss_tot': tensor(5.7639, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2286, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0338, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1154, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.1934, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.8513, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 164 #####\n",
      "{'loss_tot': tensor(6.0810, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1869, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4622, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3154, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9845, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 165 #####\n",
      "{'loss_tot': tensor(6.1023, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2197, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.4415, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.4055, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.1788, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 166 #####\n",
      "{'loss_tot': tensor(5.9246, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2165, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0342, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2771, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3047, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9929, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 167 #####\n",
      "{'loss_tot': tensor(5.8802, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2262, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2205, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3303, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0306, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 168 #####\n",
      "{'loss_tot': tensor(5.8721, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2271, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.2148, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2967, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0825, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 169 #####\n",
      "{'loss_tot': tensor(5.7979, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2540, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1095, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3386, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0412, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 170 #####\n",
      "{'loss_tot': tensor(5.7242, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2264, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0368, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.0724, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2483, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9236, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 171 #####\n",
      "{'loss_tot': tensor(5.7822, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1974, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1554, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2904, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.8310, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 172 #####\n",
      "{'loss_tot': tensor(5.7617, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1821, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1603, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.1889, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.8517, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 173 #####\n",
      "{'loss_tot': tensor(5.5722, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2185, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.9265, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2666, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9201, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 174 #####\n",
      "{'loss_tot': tensor(5.6218, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1930, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.0041, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2418, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0056, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 175 #####\n",
      "{'loss_tot': tensor(5.4761, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2339, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8365, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0520, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.8162, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 176 #####\n",
      "{'loss_tot': tensor(5.8703, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2635, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1721, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3418, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0949, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 177 #####\n",
      "{'loss_tot': tensor(5.4715, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2150, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8468, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0926, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6622, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 178 #####\n",
      "{'loss_tot': tensor(5.7401, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2085, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1080, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2316, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9019, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 179 #####\n",
      "{'loss_tot': tensor(5.4276, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2062, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0333, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8140, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0699, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7484, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 180 #####\n",
      "{'loss_tot': tensor(5.8216, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2147, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0366, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1793, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2713, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.0379, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 181 #####\n",
      "{'loss_tot': tensor(5.4140, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2192, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8031, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9127, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.4862, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 182 #####\n",
      "{'loss_tot': tensor(6.0418, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2187, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.3831, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.3948, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(4.1680, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 183 #####\n",
      "{'loss_tot': tensor(5.3731, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2192, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0362, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.7482, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0511, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6277, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 184 #####\n",
      "{'loss_tot': tensor(5.4885, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2275, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0353, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8526, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0785, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7040, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 185 #####\n",
      "{'loss_tot': tensor(5.5495, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2270, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.9223, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9973, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6166, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 186 #####\n",
      "{'loss_tot': tensor(5.4181, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2312, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.7897, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9673, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6151, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 187 #####\n",
      "{'loss_tot': tensor(5.3484, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2142, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.7325, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0118, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7075, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 188 #####\n",
      "{'loss_tot': tensor(5.5881, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2101, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.9673, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.1024, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7933, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 189 #####\n",
      "{'loss_tot': tensor(5.3441, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2163, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.7231, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0415, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7108, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 190 #####\n",
      "{'loss_tot': tensor(5.5273, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2234, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0345, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.9075, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9592, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6728, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 191 #####\n",
      "{'loss_tot': tensor(5.6692, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1853, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.0603, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.2315, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.8974, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 192 #####\n",
      "{'loss_tot': tensor(5.5950, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2154, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.9663, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.1283, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.9057, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 193 #####\n",
      "{'loss_tot': tensor(5.3017, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1902, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.7198, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9124, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.5188, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 194 #####\n",
      "{'loss_tot': tensor(5.4091, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1898, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0316, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8209, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9785, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6099, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 195 #####\n",
      "{'loss_tot': tensor(5.4149, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2367, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0358, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.7682, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0933, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.8029, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 196 #####\n",
      "{'loss_tot': tensor(5.7466, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2055, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(5.1378, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0279, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6742, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 197 #####\n",
      "{'loss_tot': tensor(5.1293, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2052, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.5325, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9116, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.5968, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 198 #####\n",
      "{'loss_tot': tensor(5.2021, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1917, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.6356, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7442, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.3012, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 199 #####\n",
      "{'loss_tot': tensor(5.2546, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1913, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.6726, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9024, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.5526, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 200 #####\n",
      "{'loss_tot': tensor(5.1506, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2071, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.5498, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9324, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.5048, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 201 #####\n",
      "{'loss_tot': tensor(5.4799, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2285, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0335, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8416, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0932, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7823, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 202 #####\n",
      "{'loss_tot': tensor(5.2340, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1801, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.6561, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9736, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.5438, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 203 #####\n",
      "{'loss_tot': tensor(5.4560, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2220, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8248, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0866, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7851, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 204 #####\n",
      "{'loss_tot': tensor(5.4062, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2207, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0329, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.7925, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9259, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.4903, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 205 #####\n",
      "{'loss_tot': tensor(5.0083, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2099, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0300, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4106, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.8734, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.4910, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 206 #####\n",
      "{'loss_tot': tensor(5.2743, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2000, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.6871, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.8671, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.3925, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 207 #####\n",
      "{'loss_tot': tensor(4.9892, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2111, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4155, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6202, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2426, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 208 #####\n",
      "{'loss_tot': tensor(5.0634, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2016, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4871, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7426, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2520, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 209 #####\n",
      "{'loss_tot': tensor(5.4639, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1847, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0296, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.8632, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.1549, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.7256, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 210 #####\n",
      "{'loss_tot': tensor(5.0314, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2145, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4376, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7877, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.4002, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 211 #####\n",
      "{'loss_tot': tensor(5.1703, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2034, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.5655, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(4.0099, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.6582, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 212 #####\n",
      "{'loss_tot': tensor(5.2474, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2195, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.6555, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7194, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2939, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 213 #####\n",
      "{'loss_tot': tensor(5.0058, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2341, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4041, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6710, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2302, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 214 #####\n",
      "{'loss_tot': tensor(5.0952, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2135, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4881, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.9308, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.4819, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 215 #####\n",
      "{'loss_tot': tensor(5.1170, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1731, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.5553, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.8831, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.5107, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 216 #####\n",
      "{'loss_tot': tensor(4.9640, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2209, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3619, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.8065, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.4866, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 217 #####\n",
      "{'loss_tot': tensor(5.0084, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2044, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4178, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.8576, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.3764, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 218 #####\n",
      "{'loss_tot': tensor(4.9289, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2248, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0302, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3288, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7484, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.3267, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 219 #####\n",
      "{'loss_tot': tensor(4.8548, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2079, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.2817, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6472, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2751, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 220 #####\n",
      "{'loss_tot': tensor(4.8935, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1990, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0319, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3179, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7617, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.3776, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 221 #####\n",
      "{'loss_tot': tensor(4.7134, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1815, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.1736, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.5792, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.1663, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 222 #####\n",
      "{'loss_tot': tensor(4.9874, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1682, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.4598, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.5905, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.1746, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 223 #####\n",
      "{'loss_tot': tensor(4.9514, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2027, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3834, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6480, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2231, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 224 #####\n",
      "{'loss_tot': tensor(4.7638, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2141, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0288, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.1856, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6373, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.1578, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 225 #####\n",
      "{'loss_tot': tensor(4.8749, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2017, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0298, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3049, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6781, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.3375, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 226 #####\n",
      "{'loss_tot': tensor(4.7071, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2051, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.1429, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.5864, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2143, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 227 #####\n",
      "{'loss_tot': tensor(4.6804, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2231, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.0936, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6327, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2404, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 228 #####\n",
      "{'loss_tot': tensor(4.9265, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2012, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3483, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7650, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2946, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 229 #####\n",
      "{'loss_tot': tensor(4.6520, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1974, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0328, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.0799, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7418, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.1280, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 230 #####\n",
      "{'loss_tot': tensor(4.5554, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1917, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0294, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.0060, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.5724, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.0407, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 231 #####\n",
      "{'loss_tot': tensor(4.8570, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1847, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3036, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6838, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2275, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 232 #####\n",
      "{'loss_tot': tensor(4.9097, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2087, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0293, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.3270, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.7358, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.3661, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 233 #####\n",
      "{'loss_tot': tensor(4.6035, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2013, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.0319, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.6992, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.2077, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Batch 234 #####\n",
      "{'loss_tot': tensor(4.7034, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1917, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.1639, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.4739, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(3.0416, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 235 #####\n",
      "{'loss_tot': tensor(4.4245, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1865, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(3.8914, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.4619, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(2.9483, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 236 #####\n",
      "{'loss_tot': tensor(4.6301, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.1755, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(4.1070, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.4711, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(2.8792, device='cuda:0', grad_fn=<DivBackward0>)}\n",
      "##### Batch 237 #####\n",
      "{'loss_tot': tensor(4.3663, device='cuda:0', grad_fn=<AddBackward0>), 'loss_beta': tensor(0.2203, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_theta': tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>), 'loss_uvd': tensor(3.8123, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl24': tensor(3.3332, device='cuda:0', grad_fn=<DivBackward0>), 'loss_xyz_smpl17': tensor(2.8063, device='cuda:0', grad_fn=<DivBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.TRY_LOAD = 'model_files/pretrained/pretrained_res34.pth'\n",
    "m = preset_model(cfg, detach=False, device='cuda')\n",
    "m.train()\n",
    "\n",
    "cfg.LOSS.ELEMENTS.UVD24_WEIGHT = 1.0\n",
    "cfg.LOSS.ELEMENTS.XYZ_SMPL24_WEIGHT = 0.1\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = builder.build_loss(cfg.LOSS)\n",
    "\n",
    "for i, batch in enumerate(tqdm(train_loader)):\n",
    "\n",
    "#     if i >= 0:\n",
    "    inps, labels, img_ids, bboxes = batch\n",
    "\n",
    "    labels = dict_to_device(labels, 'cuda')\n",
    "\n",
    "    trans_inv = labels['trans_inv'].cuda()\n",
    "    intrinsic_param = labels['intrinsic_param'].cuda()\n",
    "    root = labels['joint_root'].cuda()\n",
    "    depth_factor = labels['depth_factor'].cuda()\n",
    "    \n",
    "    \n",
    "    output_protores = m(inps.cuda(), trans_inv, intrinsic_param, root, depth_factor, None, \n",
    "                        ik_option='protores') # , labels=labels\n",
    "    \n",
    "    loss, loss_dict = criterion(output_protores, labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"##### Batch {i} #####\")\n",
    "    print(loss_dict)\n",
    "    \n",
    "    if i==1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "288deaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4370e-02, -1.0003e-01, -2.0871e-03],\n",
       "        [-7.6782e-03, -9.4711e-02, -2.5561e-01],\n",
       "        [-1.4035e-02, -9.9625e-02,  2.2711e-01],\n",
       "        [-2.2552e-03, -9.0404e-02,  1.5691e-01],\n",
       "        [-4.6625e-03, -9.2332e-02, -7.8095e-01],\n",
       "        [-1.3398e-02, -9.9144e-02,  1.1787e+00],\n",
       "        [-2.0502e-03, -9.0298e-02,  2.8995e-01],\n",
       "        [-1.3045e-02, -9.8737e-02,  1.0214e+00],\n",
       "        [-1.1444e-02, -9.7571e-02,  2.5670e+00],\n",
       "        [ 1.0098e-03, -8.7953e-02,  2.3891e-01],\n",
       "        [-1.4029e-02, -9.9471e-02,  9.2546e-01],\n",
       "        [-1.1545e-02, -9.7657e-02,  2.9813e+00],\n",
       "        [ 5.6982e-04, -8.8272e-02,  4.4607e-01],\n",
       "        [ 1.1900e-02, -7.9401e-02,  1.9440e-01],\n",
       "        [-4.4961e-03, -9.2221e-02,  6.4560e-01],\n",
       "        [ 2.0457e-02, -7.2921e-02,  1.6358e-01],\n",
       "        [-2.8467e-02, -1.1088e-01, -2.3608e-01],\n",
       "        [-5.5469e-03, -9.3064e-02,  7.6717e-01],\n",
       "        [-2.9741e-02, -1.1132e-01, -7.3476e-02],\n",
       "        [-8.4817e-03, -9.5310e-02,  1.9641e+00],\n",
       "        [ 7.3426e-03, -8.3153e-02,  2.1959e-01],\n",
       "        [-9.6788e-03, -9.6324e-02,  1.2209e+00],\n",
       "        [ 1.2663e-02, -7.8990e-02,  2.0936e-01],\n",
       "        [-1.0274e-02, -9.6852e-02,  9.2025e-01]], device='cuda:0',\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_protores.pred_uvd_jts[0].reshape(24,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8eb6abdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.0116,  0.0855,  0.0000],\n",
       "        [-0.1308, -0.0091,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.0825,  0.2082,  0.0000],\n",
       "        [-0.2700,  0.1245,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2052, -0.1024,  0.0000],\n",
       "        [ 0.1120, -0.1894,  0.0000],\n",
       "        [ 0.0713, -0.0323,  0.0000],\n",
       "        [-0.0402, -0.1529,  0.0000],\n",
       "        [ 0.0309,  0.0400,  0.0000],\n",
       "        [-0.0925, -0.0502,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_uvd_29'][1].reshape(29,3)[:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23cdf57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_weight_29'][:, :24*3][1].reshape(24,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc48074f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 1.9611e-03,  3.5017e-03,  2.0573e-02],\n",
       "        [-1.1244e-02,  1.2105e-02, -6.1533e-03],\n",
       "        [ 2.1186e-02,  1.0198e-02, -1.4764e-02],\n",
       "        [ 2.3703e-04,  1.8503e-02,  1.0682e-02],\n",
       "        [ 2.5340e-03,  1.9809e-02, -7.7835e-03],\n",
       "        [ 3.1032e-03,  6.4696e-03, -1.2500e-02],\n",
       "        [ 7.2176e-03,  5.6351e-03,  1.3921e-02],\n",
       "        [ 1.0676e-03,  8.1474e-03, -2.0640e-02],\n",
       "        [ 1.1864e-02,  1.9773e-02, -7.2135e-03],\n",
       "        [-4.2819e-03,  1.0181e-02,  2.1102e-04],\n",
       "        [ 2.3607e-02, -2.3885e-03, -1.1643e-02],\n",
       "        [-2.4415e-02, -1.3554e-02,  7.8893e-03],\n",
       "        [-6.3996e-03,  4.0183e-03, -1.2410e-04],\n",
       "        [-4.1180e-03, -1.7192e-03,  2.7290e-03],\n",
       "        [-2.2248e-02, -8.9058e-03,  1.0633e-03],\n",
       "        [ 5.3140e-03,  6.7322e-05, -8.6654e-03],\n",
       "        [-8.4888e-03, -1.2231e-02,  6.3956e-03],\n",
       "        [ 1.4611e-02,  5.7239e-03,  4.0930e-03],\n",
       "        [-3.1768e-04, -2.5064e-03, -4.0884e-03],\n",
       "        [ 1.3137e-02,  6.2795e-03,  2.5297e-03],\n",
       "        [ 4.9260e-03, -5.7919e-03, -2.6589e-03],\n",
       "        [ 3.1394e-03,  1.0809e-02, -2.7256e-03],\n",
       "        [ 3.2900e-03,  1.1143e-04,  3.6663e-03]], device='cuda:0',\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_protores.pred_xyz_jts_24_struct[0].reshape(24,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7faaee21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_xyz_24'][0].reshape(24,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddabca28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0477,  0.0050, -0.0470],\n",
       "        [ 0.0687,  0.2088, -0.0159],\n",
       "        [ 0.1324,  0.3863,  0.0412],\n",
       "        [-0.0472, -0.0046,  0.0471],\n",
       "        [ 0.0067,  0.1915,  0.0892],\n",
       "        [ 0.0528,  0.3765,  0.1523],\n",
       "        [-0.0143, -0.1151, -0.0141],\n",
       "        [-0.0514, -0.2248, -0.0312],\n",
       "        [-0.0870, -0.2512, -0.0679],\n",
       "        [-0.0898, -0.3030, -0.0521],\n",
       "        [-0.0154, -0.2054, -0.0904],\n",
       "        [-0.0588, -0.1023, -0.1591],\n",
       "        [-0.0911, -0.1859, -0.1137],\n",
       "        [-0.0713, -0.1979,  0.0304],\n",
       "        [-0.0550, -0.0970,  0.1007],\n",
       "        [-0.1278, -0.0464,  0.0474]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_protores.pred_xyz_jts_17[0].reshape(17,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9b32a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0412, -0.0004, -0.0532],\n",
       "        [ 0.0630,  0.2037, -0.0161],\n",
       "        [ 0.1341,  0.3838,  0.0363],\n",
       "        [-0.0412,  0.0011,  0.0529],\n",
       "        [ 0.0071,  0.1963,  0.0966],\n",
       "        [ 0.0560,  0.3797,  0.1494],\n",
       "        [-0.0174, -0.1163, -0.0157],\n",
       "        [-0.0559, -0.2259, -0.0298],\n",
       "        [-0.0945, -0.2500, -0.0623],\n",
       "        [-0.0921, -0.3033, -0.0494],\n",
       "        [-0.0182, -0.2048, -0.0850],\n",
       "        [-0.0594, -0.1072, -0.1481],\n",
       "        [-0.0848, -0.1914, -0.1037],\n",
       "        [-0.0746, -0.1995,  0.0333],\n",
       "        [-0.0605, -0.0977,  0.1045],\n",
       "        [-0.1317, -0.0427,  0.0592]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_xyz_17'][0].reshape(17,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f95a6a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(219.9721, device='cuda:0')\n",
      "1 tensor(86.9777, device='cuda:0')\n",
      "2 tensor(57.6795, device='cuda:0')\n",
      "3 tensor(29.3383, device='cuda:0')\n",
      "4 tensor(0.0008, device='cuda:0')\n",
      "5 tensor(31.4037, device='cuda:0')\n",
      "6 tensor(307.6479, device='cuda:0')\n",
      "7 tensor(62.9032, device='cuda:0')\n",
      "8 tensor(0.0014, device='cuda:0')\n",
      "9 tensor(0.0013, device='cuda:0')\n",
      "10 tensor(0.0012, device='cuda:0')\n",
      "11 tensor(0.0014, device='cuda:0')\n",
      "12 tensor(12.2110, device='cuda:0')\n",
      "13 tensor(3.9092, device='cuda:0')\n",
      "14 tensor(66.4815, device='cuda:0')\n",
      "15 tensor(13.7375, device='cuda:0')\n",
      "16 tensor(214.5781, device='cuda:0')\n",
      "17 tensor(0.0011, device='cuda:0')\n",
      "18 tensor(58.9240, device='cuda:0')\n",
      "19 tensor(0.0015, device='cuda:0')\n",
      "20 tensor(96.8480, device='cuda:0')\n",
      "21 tensor(79.2419, device='cuda:0')\n",
      "22 tensor(25.4064, device='cuda:0')\n",
      "23 tensor(6.3708, device='cuda:0')\n",
      "24 tensor(7.5052, device='cuda:0')\n",
      "25 tensor(181.4329, device='cuda:0')\n",
      "26 tensor(0.0012, device='cuda:0')\n",
      "27 tensor(71.0691, device='cuda:0')\n",
      "28 tensor(6.5441, device='cuda:0')\n",
      "29 tensor(12.8907, device='cuda:0')\n",
      "30 tensor(0.0012, device='cuda:0')\n",
      "31 tensor(67.1476, device='cuda:0')\n",
      "32 tensor(14.8226, device='cuda:0')\n",
      "33 tensor(6.5286, device='cuda:0')\n",
      "34 tensor(0.0013, device='cuda:0')\n",
      "35 tensor(26.8954, device='cuda:0')\n",
      "36 tensor(7.1146, device='cuda:0')\n",
      "37 tensor(79.0182, device='cuda:0')\n",
      "38 tensor(34.2338, device='cuda:0')\n",
      "39 tensor(17.4213, device='cuda:0')\n",
      "40 tensor(0.0012, device='cuda:0')\n",
      "41 tensor(0.0032, device='cuda:0')\n",
      "42 tensor(0.0014, device='cuda:0')\n",
      "43 tensor(97.2021, device='cuda:0')\n",
      "44 tensor(299.4141, device='cuda:0')\n",
      "45 tensor(56.6199, device='cuda:0')\n",
      "46 tensor(180.6772, device='cuda:0')\n",
      "47 tensor(8.6793, device='cuda:0')\n",
      "48 tensor(22.6562, device='cuda:0')\n",
      "49 tensor(264.7222, device='cuda:0')\n",
      "50 tensor(2.6650, device='cuda:0')\n",
      "51 tensor(153.9393, device='cuda:0')\n",
      "52 tensor(50.1554, device='cuda:0')\n",
      "53 tensor(143.9177, device='cuda:0')\n",
      "54 tensor(96.4808, device='cuda:0')\n",
      "55 tensor(125.4570, device='cuda:0')\n",
      "56 tensor(71.2271, device='cuda:0')\n",
      "57 tensor(353.8489, device='cuda:0')\n",
      "58 tensor(76.9199, device='cuda:0')\n",
      "59 tensor(0.0017, device='cuda:0')\n",
      "60 tensor(3.7269, device='cuda:0')\n",
      "61 tensor(0.0011, device='cuda:0')\n",
      "62 tensor(79.3151, device='cuda:0')\n",
      "63 tensor(0.0016, device='cuda:0')\n",
      "64 tensor(0.0024, device='cuda:0')\n",
      "65 tensor(76.3635, device='cuda:0')\n",
      "66 tensor(165.9635, device='cuda:0')\n",
      "67 tensor(18.2793, device='cuda:0')\n",
      "68 tensor(244.3964, device='cuda:0')\n",
      "69 tensor(41.1482, device='cuda:0')\n",
      "70 tensor(65.9319, device='cuda:0')\n",
      "71 tensor(6.8235, device='cuda:0')\n",
      "72 tensor(45.8207, device='cuda:0')\n",
      "73 tensor(34.8555, device='cuda:0')\n",
      "74 tensor(31.2041, device='cuda:0')\n",
      "75 tensor(0.0023, device='cuda:0')\n",
      "76 tensor(156.7355, device='cuda:0')\n",
      "77 tensor(17.1667, device='cuda:0')\n",
      "78 tensor(36.3808, device='cuda:0')\n",
      "79 tensor(0.0016, device='cuda:0')\n",
      "80 tensor(2.0587, device='cuda:0')\n",
      "81 tensor(161.3665, device='cuda:0')\n",
      "82 tensor(5.4148, device='cuda:0')\n",
      "83 tensor(83.4236, device='cuda:0')\n",
      "84 tensor(0.0009, device='cuda:0')\n",
      "85 tensor(0.0012, device='cuda:0')\n",
      "86 tensor(154.1368, device='cuda:0')\n",
      "87 tensor(42.6456, device='cuda:0')\n",
      "88 tensor(6.0457, device='cuda:0')\n",
      "89 tensor(48.0314, device='cuda:0')\n",
      "90 tensor(109.0626, device='cuda:0')\n",
      "91 tensor(21.7395, device='cuda:0')\n",
      "92 tensor(0.0016, device='cuda:0')\n",
      "93 tensor(0., device='cuda:0')\n",
      "94 tensor(90.7647, device='cuda:0')\n",
      "95 tensor(213.8746, device='cuda:0')\n",
      "96 tensor(106.0004, device='cuda:0')\n",
      "97 tensor(5.3881, device='cuda:0')\n",
      "98 tensor(4.4923, device='cuda:0')\n",
      "99 tensor(93.9716, device='cuda:0')\n",
      "100 tensor(85.1314, device='cuda:0')\n",
      "101 tensor(0.0010, device='cuda:0')\n",
      "102 tensor(0.0011, device='cuda:0')\n",
      "103 tensor(79.2601, device='cuda:0')\n",
      "104 tensor(0.0012, device='cuda:0')\n",
      "105 tensor(15.7119, device='cuda:0')\n",
      "106 tensor(10.6557, device='cuda:0')\n",
      "107 tensor(8.4709, device='cuda:0')\n",
      "108 tensor(0.0011, device='cuda:0')\n",
      "109 tensor(219.6982, device='cuda:0')\n",
      "110 tensor(26.8473, device='cuda:0')\n",
      "111 tensor(15.0297, device='cuda:0')\n",
      "112 tensor(13.7614, device='cuda:0')\n",
      "113 tensor(49.6150, device='cuda:0')\n",
      "114 tensor(5.4899, device='cuda:0')\n",
      "115 tensor(52.0302, device='cuda:0')\n",
      "116 tensor(1.7976, device='cuda:0')\n",
      "117 tensor(5.4610, device='cuda:0')\n",
      "118 tensor(29.3777, device='cuda:0')\n",
      "119 tensor(201.9103, device='cuda:0')\n",
      "120 tensor(57.7040, device='cuda:0')\n",
      "121 tensor(0.0020, device='cuda:0')\n",
      "122 tensor(0.0007, device='cuda:0')\n",
      "123 tensor(2.8070, device='cuda:0')\n",
      "124 tensor(50.3286, device='cuda:0')\n",
      "125 tensor(5.7587, device='cuda:0')\n",
      "126 tensor(4.1623, device='cuda:0')\n",
      "127 tensor(15.7688, device='cuda:0')\n",
      "128 tensor(50.9087, device='cuda:0')\n",
      "129 tensor(0.0019, device='cuda:0')\n",
      "130 tensor(28.8531, device='cuda:0')\n",
      "131 tensor(72.4558, device='cuda:0')\n",
      "132 tensor(14.4188, device='cuda:0')\n",
      "133 tensor(12.3806, device='cuda:0')\n",
      "134 tensor(10.3173, device='cuda:0')\n",
      "135 tensor(104.7442, device='cuda:0')\n",
      "136 tensor(88.8758, device='cuda:0')\n",
      "137 tensor(34.7934, device='cuda:0')\n",
      "138 tensor(170.8466, device='cuda:0')\n",
      "139 tensor(43.3487, device='cuda:0')\n",
      "140 tensor(59.1717, device='cuda:0')\n",
      "141 tensor(63.6916, device='cuda:0')\n",
      "142 tensor(59.1623, device='cuda:0')\n",
      "143 tensor(0.0019, device='cuda:0')\n",
      "144 tensor(7.0571, device='cuda:0')\n",
      "145 tensor(6.9332, device='cuda:0')\n",
      "146 tensor(0.0023, device='cuda:0')\n",
      "147 tensor(58.4840, device='cuda:0')\n",
      "148 tensor(25.8409, device='cuda:0')\n",
      "149 tensor(14.7232, device='cuda:0')\n",
      "150 tensor(10.1520, device='cuda:0')\n",
      "151 tensor(0.0014, device='cuda:0')\n",
      "152 tensor(84.2405, device='cuda:0')\n",
      "153 tensor(0.0011, device='cuda:0')\n",
      "154 tensor(41.2713, device='cuda:0')\n",
      "155 tensor(68.8936, device='cuda:0')\n",
      "156 tensor(39.7936, device='cuda:0')\n",
      "157 tensor(0.0011, device='cuda:0')\n",
      "158 tensor(76.7427, device='cuda:0')\n",
      "159 tensor(102.6232, device='cuda:0')\n",
      "160 tensor(0.0010, device='cuda:0')\n",
      "161 tensor(21.2250, device='cuda:0')\n",
      "162 tensor(4.5062, device='cuda:0')\n",
      "163 tensor(0.0015, device='cuda:0')\n",
      "164 tensor(0.0012, device='cuda:0')\n",
      "165 tensor(0.0011, device='cuda:0')\n",
      "166 tensor(36.7080, device='cuda:0')\n",
      "167 tensor(276.8066, device='cuda:0')\n",
      "168 tensor(121.8245, device='cuda:0')\n",
      "169 tensor(33.6885, device='cuda:0')\n",
      "170 tensor(28.8807, device='cuda:0')\n",
      "171 tensor(0.9557, device='cuda:0')\n",
      "172 tensor(0.0012, device='cuda:0')\n",
      "173 tensor(45.4515, device='cuda:0')\n",
      "174 tensor(41.7696, device='cuda:0')\n",
      "175 tensor(46.9811, device='cuda:0')\n",
      "176 tensor(0., device='cuda:0')\n",
      "177 tensor(33.1827, device='cuda:0')\n",
      "178 tensor(15.7125, device='cuda:0')\n",
      "179 tensor(0.0015, device='cuda:0')\n",
      "180 tensor(138.8751, device='cuda:0')\n",
      "181 tensor(8.0773, device='cuda:0')\n",
      "182 tensor(61.0081, device='cuda:0')\n",
      "183 tensor(8.6767, device='cuda:0')\n",
      "184 tensor(0., device='cuda:0')\n",
      "185 tensor(152.3301, device='cuda:0')\n",
      "186 tensor(8.0454, device='cuda:0')\n",
      "187 tensor(97.3655, device='cuda:0')\n",
      "188 tensor(10.9509, device='cuda:0')\n",
      "189 tensor(6.0324, device='cuda:0')\n",
      "190 tensor(34.1607, device='cuda:0')\n",
      "191 tensor(33.0347, device='cuda:0')\n",
      "192 tensor(37.6310, device='cuda:0')\n",
      "193 tensor(8.9039, device='cuda:0')\n",
      "194 tensor(8.1545, device='cuda:0')\n",
      "195 tensor(43.1350, device='cuda:0')\n",
      "196 tensor(0.0012, device='cuda:0')\n",
      "197 tensor(35.8606, device='cuda:0')\n",
      "198 tensor(69.3074, device='cuda:0')\n",
      "199 tensor(34.8976, device='cuda:0')\n",
      "200 tensor(94.6215, device='cuda:0')\n",
      "201 tensor(76.7268, device='cuda:0')\n",
      "202 tensor(40.3906, device='cuda:0')\n",
      "203 tensor(73.6954, device='cuda:0')\n",
      "204 tensor(68.3030, device='cuda:0')\n",
      "205 tensor(77.3292, device='cuda:0')\n",
      "206 tensor(0.0008, device='cuda:0')\n",
      "207 tensor(195.2597, device='cuda:0')\n",
      "208 tensor(156.4929, device='cuda:0')\n",
      "209 tensor(321.7966, device='cuda:0')\n",
      "210 tensor(19.4075, device='cuda:0')\n",
      "211 tensor(110.8125, device='cuda:0')\n",
      "212 tensor(73.4377, device='cuda:0')\n",
      "213 tensor(0.0013, device='cuda:0')\n",
      "214 tensor(8.8301, device='cuda:0')\n",
      "215 tensor(0.0017, device='cuda:0')\n",
      "216 tensor(0.0012, device='cuda:0')\n",
      "217 tensor(0.0011, device='cuda:0')\n",
      "218 tensor(10.5728, device='cuda:0')\n",
      "219 tensor(0.0008, device='cuda:0')\n",
      "220 tensor(9.4483, device='cuda:0')\n",
      "221 tensor(78.4706, device='cuda:0')\n",
      "222 tensor(104.0622, device='cuda:0')\n",
      "223 tensor(37.8993, device='cuda:0')\n",
      "224 tensor(0.0008, device='cuda:0')\n",
      "225 tensor(0.0014, device='cuda:0')\n",
      "226 tensor(7.6630, device='cuda:0')\n",
      "227 tensor(135.2135, device='cuda:0')\n",
      "228 tensor(99.3983, device='cuda:0')\n",
      "229 tensor(14.3641, device='cuda:0')\n",
      "230 tensor(92.9329, device='cuda:0')\n",
      "231 tensor(133.7774, device='cuda:0')\n",
      "232 tensor(0., device='cuda:0')\n",
      "233 tensor(15.8929, device='cuda:0')\n",
      "234 tensor(0.9507, device='cuda:0')\n",
      "235 tensor(40.9149, device='cuda:0')\n",
      "236 tensor(81.9806, device='cuda:0')\n",
      "237 tensor(49.7653, device='cuda:0')\n",
      "238 tensor(115.9867, device='cuda:0')\n",
      "239 tensor(95.4987, device='cuda:0')\n",
      "240 tensor(187.9395, device='cuda:0')\n",
      "241 tensor(26.5561, device='cuda:0')\n",
      "242 tensor(0.0008, device='cuda:0')\n",
      "243 tensor(20.1508, device='cuda:0')\n",
      "244 tensor(0.0011, device='cuda:0')\n",
      "245 tensor(28.4170, device='cuda:0')\n",
      "246 tensor(8.2203, device='cuda:0')\n",
      "247 tensor(51.4426, device='cuda:0')\n",
      "248 tensor(162.5103, device='cuda:0')\n",
      "249 tensor(2.0215, device='cuda:0')\n",
      "250 tensor(0.0015, device='cuda:0')\n",
      "251 tensor(74.4699, device='cuda:0')\n",
      "252 tensor(63.4642, device='cuda:0')\n",
      "253 tensor(39.5650, device='cuda:0')\n",
      "254 tensor(298.7007, device='cuda:0')\n",
      "255 tensor(3.1082, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def weighted_l1_loss(input, target, weights, size_average):\n",
    "    input = input * 64\n",
    "    target = target * 64\n",
    "    out = torch.abs(input - target)\n",
    "    out = out * weights\n",
    "    if size_average and weights.sum() > 0:\n",
    "        return out.sum() / weights.sum()\n",
    "    else:\n",
    "        return out.sum()\n",
    "\n",
    "pred_uvd = output_protores.pred_uvd_jts\n",
    "target_uvd = labels['target_uvd_29'][:, :pred_uvd.shape[1]]\n",
    "target_uvd_weight = labels['target_weight_29'][:, :pred_uvd.shape[1]]\n",
    "\n",
    "for i in range(pred_uvd.shape[0]):\n",
    "    uvd_loss = weighted_l1_loss(pred_uvd[[i]], target_uvd[[i]],\n",
    "                                weights=target_uvd_weight[[i]], size_average=True)\n",
    "    print(i, uvd_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15220f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_uvd_weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65266f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['trans_inv', 'intrinsic_param', 'joint_root', 'depth_factor', 'target_uvd_29', 'target_xyz_24', 'target_weight_24', 'target_weight_29', 'target_xyz_17', 'target_weight_17', 'target_theta', 'target_beta', 'target_smpl_weight', 'target_theta_weight', 'target_twist', 'target_twist_weight'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282ed24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd284c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3406baea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 18 17:28:37 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    59W / 400W |  23010MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   34C    P0    73W / 400W |      3MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c932672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f620c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18af35b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.58s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "gt_val_dataset_3dpw = PW3D(cfg=cfg,\n",
    "                           ann_file='3DPW_test_new.json',\n",
    "                           train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "583254c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "gt_val_dataset_3dpw_subset = Subset(gt_val_dataset_3dpw, \n",
    "                                    indices=np.random.choice(np.arange(len(gt_val_dataset_3dpw)), \n",
    "                                                             size=int(0.1*len(gt_val_dataset_3dpw)), replace=False))\n",
    "\n",
    "gt_val_loader = DataLoader(gt_val_dataset_3dpw, \n",
    "                           batch_size=4, \n",
    "                           shuffle=False, \n",
    "                           num_workers=8, \n",
    "                           drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c06c3ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n",
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/hydra/utils.py:32: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if OmegaConf.is_none(config):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from model_files/pretrained/pretrained_res34.pth...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepposeTransformerNeSMPL24(\n",
       "  (preact): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (protores_model): SmplModel(\n",
       "    (smpl_male): SmplFK(\n",
       "      Gender: NEUTRAL\n",
       "      Number of joints: 24\n",
       "      Betas: 10\n",
       "      (vertex_joint_selector): VertexJointSelector()\n",
       "    )\n",
       "    (smpl_female): SmplFK(\n",
       "      Gender: NEUTRAL\n",
       "      Number of joints: 24\n",
       "      Betas: 10\n",
       "      (vertex_joint_selector): VertexJointSelector()\n",
       "    )\n",
       "    (smpl_neutral): SmplFK(\n",
       "      Gender: NEUTRAL\n",
       "      Number of joints: 24\n",
       "      Betas: 10\n",
       "      (vertex_joint_selector): VertexJointSelector()\n",
       "    )\n",
       "    (test_fk_metric): MeanSquaredError()\n",
       "    (test_position_metric): MeanSquaredError()\n",
       "    (test_rotation_metric): RotationMatrixError()\n",
       "    (net): WeightedRelationNetSmpl(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Embedding(\n",
       "          (projection): Linear(in_features=65, out_features=32, bias=True)\n",
       "        )\n",
       "        (1): Embedding(\n",
       "          (projection): Linear(in_features=65, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (encoder): WeightedProtoEncoder(\n",
       "        (blocks): ModuleList(\n",
       "          (0): FCBlock(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (backward_projection): Linear(in_features=82, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=82, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): FCBlock(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (backward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): FCBlock(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (backward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder_stage1): ProtoDecoder(\n",
       "        (blocks): ModuleList(\n",
       "          (0): FCBlockNorm(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=72, bias=True)\n",
       "            (backward_projection): Linear(in_features=1035, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1035, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): FCBlockNorm(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=72, bias=True)\n",
       "            (backward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): FCBlockNorm(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=72, bias=True)\n",
       "            (backward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decoder_stage2): ProtoDecoder(\n",
       "        (blocks): ModuleList(\n",
       "          (0): FCBlockNorm(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=144, bias=True)\n",
       "            (backward_projection): Linear(in_features=1107, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1107, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): FCBlockNorm(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=144, bias=True)\n",
       "            (backward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): FCBlockNorm(\n",
       "            (forward_projection): Linear(in_features=1024, out_features=144, bias=True)\n",
       "            (backward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fc_layers): ModuleList(\n",
       "              (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (1): Dropout(p=0.01, inplace=False)\n",
       "              (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (relu_layers): ModuleList(\n",
       "              (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (1): Identity()\n",
       "              (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "              (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "            )\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (validation_fixed_fk_metric): MeanSquaredError()\n",
       "    (validation_fixed_position_metric): MeanSquaredError()\n",
       "    (validation_fixed_rotation_metric): RotationMatrixError()\n",
       "    (validation_fixed_mpjpe_metric): MPJPE()\n",
       "    (validation_fixed_pampjpe_metric): PA_MPJPE()\n",
       "    (validation_random_fk_metric): MeanSquaredError()\n",
       "    (validation_random_position_metric): MeanSquaredError()\n",
       "    (validation_random_rotation_metric): RotationMatrixError()\n",
       "    (validation_random_mpjpe_metric): MPJPE()\n",
       "    (validation_random_pampjpe_metric): PA_MPJPE()\n",
       "  )\n",
       "  (deconv_layers): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (final_layer): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (smpl): SMPL_layer()\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (decshape): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (decphi): Linear(in_features=1024, out_features=46, bias=True)\n",
       "  (decleaf): Linear(in_features=1024, out_features=20, bias=True)\n",
       "  (joint_embedding_projection): Linear(in_features=32, out_features=512, bias=True)\n",
       "  (mha): MultiHeadAttention(\n",
       "    in_features=512, head_num=8, bias=True, activation=<function relu at 0x7f024e0484d0>\n",
       "    (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (fc_block): FCBlock(\n",
       "    (forward_projection): Linear(in_features=512, out_features=3, bias=True)\n",
       "    (backward_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (fc_layers): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): Dropout(p=0.01, inplace=False)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (relu_layers): ModuleList(\n",
       "      (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (1): Identity()\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (mha_sa): MultiHeadAttention(\n",
       "    in_features=512, head_num=8, bias=True, activation=<function relu at 0x7f024e0484d0>\n",
       "    (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (fc_block_sa): FCBlock(\n",
       "    (forward_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (backward_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (fc_layers): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): Dropout(p=0.01, inplace=False)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (relu_layers): ModuleList(\n",
       "      (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (1): Identity()\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (ffn_src): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (fc_layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Dropout(p=0.01, inplace=False)\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (relu_layers): ModuleList(\n",
       "          (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (1): Identity()\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (fc_layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Dropout(p=0.01, inplace=False)\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (relu_layers): ModuleList(\n",
       "          (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (1): Identity()\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (ffn_tgt): ModuleList(\n",
       "      (0): ResidualBlock(\n",
       "        (fc_layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Dropout(p=0.01, inplace=False)\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (relu_layers): ModuleList(\n",
       "          (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (1): Identity()\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (fc_layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Dropout(p=0.01, inplace=False)\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (relu_layers): ModuleList(\n",
       "          (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (1): Identity()\n",
       "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (mha_src): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        in_features=512, head_num=8, bias=True, activation=None\n",
       "        (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        in_features=512, head_num=8, bias=True, activation=None\n",
       "        (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mha_tgt): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        in_features=512, head_num=8, bias=True, activation=None\n",
       "        (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        in_features=512, head_num=8, bias=True, activation=None\n",
       "        (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (mha_cross): ModuleList(\n",
       "      (0): MultiHeadAttention(\n",
       "        in_features=512, head_num=8, bias=True, activation=None\n",
       "        (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (1): MultiHeadAttention(\n",
       "        in_features=512, head_num=8, bias=True, activation=None\n",
       "        (linear_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (linear_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm_src): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "      (1): LayerNorm()\n",
       "    )\n",
       "    (layer_norm_tgt): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "      (1): LayerNorm()\n",
       "    )\n",
       "    (layer_norm_cross): ModuleList(\n",
       "      (0): LayerNorm()\n",
       "      (1): LayerNorm()\n",
       "    )\n",
       "    (input_projection_src): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (input_projection_tgt): Linear(in_features=32, out_features=512, bias=True)\n",
       "    (output_projection): Linear(in_features=512, out_features=71, bias=True)\n",
       "  )\n",
       "  (pos_embedding): PositionEmbeddingLearned(\n",
       "    (row_embed): Embedding(8, 256)\n",
       "    (col_embed): Embedding(8, 256)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.MODEL.TRY_LOAD = 'model_files/pretrained/pretrained_res34.pth'\n",
    "\n",
    "m = preset_model(cfg, detach=True, device='cuda')\n",
    "m.eval()\n",
    "\n",
    "criterion = builder.build_loss(cfg.LOSS)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "64867be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_protores = m(inps.cuda(), trans_inv, intrinsic_param, root, depth_factor, None, ik_option='protores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c7fd5e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(19.2637, device='cuda:0'),\n",
       " {'loss_tot': tensor(19.2637, device='cuda:0'),\n",
       "  'loss_beta': tensor(0.0002, device='cuda:0'),\n",
       "  'loss_theta': tensor(0.0417, device='cuda:0'),\n",
       "  'loss_uvd': tensor(19.2631, device='cuda:0'),\n",
       "  'loss_xyz_smpl24': tensor(8.1972, device='cuda:0'),\n",
       "  'loss_xyz_smpl17': tensor(9.9651, device='cuda:0')})"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n",
    "\n",
    "\n",
    "criterion(output_protores, dict_to_device(labels, 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a30e7fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['trans_inv', 'intrinsic_param', 'joint_root', 'depth_factor', 'target_uvd_29', 'target_xyz_24', 'target_weight_24', 'target_weight_29', 'target_xyz_17', 'target_weight_17', 'target_theta', 'target_beta', 'target_smpl_weight', 'target_theta_weight', 'target_twist', 'target_twist_weight'])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "36de3690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 6.6769e-04,  0.0000e+00, -6.8419e-01],\n",
       "         [ 0.0000e+00,  6.6796e-04, -7.0229e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 6.6769e-04,  0.0000e+00, -6.8419e-01],\n",
       "         [ 0.0000e+00,  6.6796e-04, -7.0229e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 6.6769e-04,  0.0000e+00, -6.8419e-01],\n",
       "         [ 0.0000e+00,  6.6796e-04, -7.0229e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 8.7332e-04,  0.0000e+00, -4.4762e-01],\n",
       "         [ 0.0000e+00,  8.7429e-04, -4.5066e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['intrinsic_param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "9b03be38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.],\n",
       "        [2000.]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['depth_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "77da977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = 0\n",
    "\n",
    "trans_inv = labels['trans_inv'].cuda()\n",
    "intrinsic_param = labels['intrinsic_param'].cuda()\n",
    "root = labels['joint_root'].cuda()\n",
    "depth_factor = labels['depth_factor'].cuda()\n",
    "\n",
    "\n",
    "output = m.smpl.forward(\n",
    "                pose_axis_angle=labels['target_theta'].cuda(), \n",
    "                betas=labels['target_beta'].cuda(), \n",
    "                transl=None,\n",
    "                global_orient=None,\n",
    "                return_verts=True\n",
    "            )\n",
    "pred_vertices = output.vertices.float()\n",
    "pred_xyz_jts_24_struct = output.joints.float() / 2.0\n",
    "pred_xyz_jts_17 = output.joints_from_verts.float() / 2.0\n",
    "\n",
    "pred_uvd_jts_24 = m.cam_to_uvd(pred_xyz_jts_24_struct, trans_inv, intrinsic_param, root, depth_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a0b5c891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0149, -0.0388,  0.0000],\n",
       "        [-0.0167, -0.0025, -0.0034],\n",
       "        [ 0.0353, -0.0004,  0.0243],\n",
       "        [ 0.0263, -0.0795, -0.0247],\n",
       "        [-0.0210,  0.1539,  0.0153],\n",
       "        [ 0.0356,  0.1346,  0.1225],\n",
       "        [ 0.0285, -0.1386, -0.0373],\n",
       "        [ 0.0099,  0.3121,  0.0527],\n",
       "        [ 0.0680,  0.2927,  0.1023],\n",
       "        [ 0.0246, -0.1616, -0.0291],\n",
       "        [-0.0203,  0.3093,  0.1045],\n",
       "        [ 0.0677,  0.2945,  0.1656],\n",
       "        [ 0.0335, -0.2586, -0.0662],\n",
       "        [-0.0024, -0.2154, -0.0671],\n",
       "        [ 0.0631, -0.2140, -0.0428],\n",
       "        [ 0.0270, -0.2911, -0.0517],\n",
       "        [-0.0418, -0.2052, -0.0761],\n",
       "        [ 0.0984, -0.2028, -0.0188],\n",
       "        [-0.0710, -0.1009, -0.0334],\n",
       "        [ 0.1049, -0.1015,  0.0275],\n",
       "        [-0.1047, -0.0372,  0.0511],\n",
       "        [ 0.0972, -0.0238,  0.1102],\n",
       "        [-0.1105, -0.0099,  0.0741],\n",
       "        [ 0.0939,  0.0048,  0.1298]], device='cuda:0')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_uvd_jts_24[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b8f02c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4932e-02, -3.8804e-02,  0.0000e+00],\n",
       "        [-1.6659e-02, -2.5053e-03, -3.3872e-03],\n",
       "        [ 3.5293e-02, -3.4532e-04,  2.4351e-02],\n",
       "        [ 2.6300e-02, -7.9473e-02, -2.4659e-02],\n",
       "        [-2.0970e-02,  1.5396e-01,  1.5279e-02],\n",
       "        [ 3.5581e-02,  1.3463e-01,  1.2256e-01],\n",
       "        [ 2.8535e-02, -1.3861e-01, -3.7340e-02],\n",
       "        [ 9.9413e-03,  3.1204e-01,  5.2709e-02],\n",
       "        [ 6.8013e-02,  2.9257e-01,  1.0229e-01],\n",
       "        [ 2.4635e-02, -1.6159e-01, -2.9095e-02],\n",
       "        [-2.0312e-02,  3.0919e-01,  1.0450e-01],\n",
       "        [ 6.7685e-02,  2.9451e-01,  1.6569e-01],\n",
       "        [ 3.3479e-02, -2.5860e-01, -6.6225e-02],\n",
       "        [-2.3775e-03, -2.1541e-01, -6.7052e-02],\n",
       "        [ 6.3113e-02, -2.1397e-01, -4.2832e-02],\n",
       "        [ 2.6997e-02, -2.9114e-01, -5.1722e-02],\n",
       "        [-4.1759e-02, -2.0518e-01, -7.6046e-02],\n",
       "        [ 9.8422e-02, -2.0277e-01, -1.8816e-02],\n",
       "        [-7.0982e-02, -1.0085e-01, -3.3412e-02],\n",
       "        [ 1.0490e-01, -1.0152e-01,  2.7555e-02],\n",
       "        [-1.0470e-01, -3.7163e-02,  5.1156e-02],\n",
       "        [ 9.7203e-02, -2.3784e-02,  1.1031e-01],\n",
       "        [-1.1048e-01, -9.9529e-03,  7.4041e-02],\n",
       "        [ 9.3900e-02,  4.7458e-03,  1.2983e-01],\n",
       "        [ 3.3987e-02, -3.8315e-01, -7.2671e-02],\n",
       "        [-1.1482e-01,  1.7523e-02,  1.1101e-01],\n",
       "        [ 8.2219e-02,  3.4988e-02,  1.5602e-01],\n",
       "        [-2.8986e-02,  2.9589e-01,  1.3637e-01],\n",
       "        [ 4.4336e-02,  2.9133e-01,  1.8940e-01]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_uvd_29'].reshape(-1, 29, 3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "71d8c87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9605e-08,  2.9802e-08,  0.0000e+00],\n",
       "        [-1.1027e-06,  5.7817e-06,  6.5917e-06],\n",
       "        [ 3.2783e-06, -1.3381e-05, -9.0320e-06],\n",
       "        [-1.6093e-06, -6.2883e-06, -4.3958e-06],\n",
       "        [-4.1425e-06, -2.2471e-05, -5.6149e-06],\n",
       "        [-9.2983e-06, -3.1471e-05, -2.9542e-05],\n",
       "        [ 1.9073e-06, -4.3213e-06, -5.6177e-06],\n",
       "        [-6.6161e-06,  3.9220e-05,  9.7640e-06],\n",
       "        [ 2.9743e-05,  7.9393e-05, -2.0757e-05],\n",
       "        [-4.1127e-06, -7.5102e-06, -7.5698e-06],\n",
       "        [-5.6326e-06,  8.1182e-05,  3.3200e-05],\n",
       "        [ 1.3053e-05, -1.1921e-06, -4.7132e-05],\n",
       "        [-3.2187e-06, -1.5736e-05,  7.3016e-07],\n",
       "        [-1.7881e-07, -4.2021e-06, -6.3479e-06],\n",
       "        [-5.2452e-06, -4.2021e-06, -6.5938e-06],\n",
       "        [-5.0068e-06, -4.7684e-07, -7.5698e-06],\n",
       "        [-7.3016e-06, -1.5914e-05, -1.0252e-05],\n",
       "        [-8.6427e-06, -7.7784e-06, -1.9532e-05],\n",
       "        [ 7.4506e-07, -2.6226e-06,  7.3388e-07],\n",
       "        [-1.8477e-05,  1.0610e-05, -9.5200e-06],\n",
       "        [ 2.8104e-05, -2.3663e-05, -3.1985e-05],\n",
       "        [-9.9540e-06, -3.9577e-05, -6.6653e-05],\n",
       "        [-1.8656e-05,  5.5641e-05,  7.3001e-05],\n",
       "        [-1.3769e-05,  7.9870e-06, -2.4661e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_uvd_jts_24[0] - labels['target_uvd_29'].reshape(-1, 29, 3)[:, :24][0].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a8a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbae4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089beb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080e295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "40188498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0336, -0.0410,  0.0000],\n",
      "        [-0.0205, -0.0103, -0.0036],\n",
      "        [ 0.0418,  0.0146,  0.0245],\n",
      "        [ 0.0650, -0.0857, -0.0246],\n",
      "        [-0.0932,  0.1783,  0.0166],\n",
      "        [-0.0161,  0.1788,  0.1232],\n",
      "        [ 0.0931, -0.1568, -0.0371],\n",
      "        [-0.1231,  0.3842,  0.0545],\n",
      "        [-0.0438,  0.3854,  0.1040],\n",
      "        [ 0.0980, -0.1866, -0.0289],\n",
      "        [-0.1586,  0.3678,  0.1064],\n",
      "        [-0.0451,  0.3877,  0.1674],\n",
      "        [ 0.1499, -0.3014, -0.0655],\n",
      "        [ 0.0879, -0.2638, -0.0668],\n",
      "        [ 0.1672, -0.2344, -0.0421],\n",
      "        [ 0.1559, -0.3439, -0.0510],\n",
      "        [ 0.0358, -0.2679, -0.0769],\n",
      "        [ 0.2059, -0.2061, -0.0183],\n",
      "        [-0.0446, -0.1514, -0.0387],\n",
      "        [ 0.1722, -0.0785,  0.0257],\n",
      "        [-0.1141, -0.0860,  0.0440],\n",
      "        [ 0.1258,  0.0107,  0.1089],\n",
      "        [-0.1330, -0.0549,  0.0664],\n",
      "        [ 0.1086,  0.0433,  0.1290],\n",
      "        [ 0.2045, -0.4528, -0.0715],\n",
      "        [-0.1503, -0.0227,  0.1029],\n",
      "        [ 0.0803,  0.0740,  0.1553],\n",
      "        [-0.1635,  0.3477,  0.1382],\n",
      "        [-0.0723,  0.3737,  0.1911]])\n",
      "tensor([[ 0.0336, -0.0410,  0.0000],\n",
      "        [-0.0205, -0.0103, -0.0036],\n",
      "        [ 0.0418,  0.0146,  0.0245],\n",
      "        [ 0.0650, -0.0857, -0.0246],\n",
      "        [-0.0932,  0.1783,  0.0166],\n",
      "        [-0.0161,  0.1788,  0.1232],\n",
      "        [ 0.0931, -0.1568, -0.0371],\n",
      "        [-0.1231,  0.3842,  0.0545],\n",
      "        [-0.0438,  0.3854,  0.1040],\n",
      "        [ 0.0980, -0.1866, -0.0289],\n",
      "        [-0.1586,  0.3678,  0.1064],\n",
      "        [-0.0451,  0.3877,  0.1674],\n",
      "        [ 0.1499, -0.3014, -0.0655],\n",
      "        [ 0.0879, -0.2638, -0.0668],\n",
      "        [ 0.1672, -0.2344, -0.0421],\n",
      "        [ 0.1559, -0.3439, -0.0510],\n",
      "        [ 0.0358, -0.2679, -0.0769],\n",
      "        [ 0.2059, -0.2061, -0.0183],\n",
      "        [-0.0446, -0.1514, -0.0387],\n",
      "        [ 0.1722, -0.0785,  0.0257],\n",
      "        [-0.1141, -0.0860,  0.0440],\n",
      "        [ 0.1258,  0.0107,  0.1089],\n",
      "        [-0.1330, -0.0549,  0.0664],\n",
      "        [ 0.1086,  0.0433,  0.1290],\n",
      "        [ 0.2045, -0.4528, -0.0715],\n",
      "        [-0.1503, -0.0227,  0.1029],\n",
      "        [ 0.0803,  0.0740,  0.1553],\n",
      "        [-0.1635,  0.3477,  0.1382],\n",
      "        [-0.0723,  0.3737,  0.1911]], device='cuda:0')\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.9407e-08, -8.9407e-08,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1921e-07,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.9605e-08, -5.9605e-08,  0.0000e+00],\n",
      "        [ 2.9802e-08, -5.9605e-08,  0.0000e+00],\n",
      "        [ 1.7881e-07,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.9407e-08,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.9802e-08,  1.7881e-07,  0.0000e+00],\n",
      "        [ 0.0000e+00,  5.9605e-08,  0.0000e+00],\n",
      "        [ 8.9407e-08,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.9605e-08, -5.9605e-08,  0.0000e+00],\n",
      "        [-5.9605e-08, -2.9802e-08,  0.0000e+00],\n",
      "        [ 1.1921e-07, -2.9802e-08,  0.0000e+00],\n",
      "        [ 0.0000e+00, -8.9407e-08,  0.0000e+00],\n",
      "        [-1.1921e-07, -5.9605e-08,  0.0000e+00],\n",
      "        [-5.9605e-08, -2.9802e-08,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.1921e-07,  2.9802e-08,  0.0000e+00],\n",
      "        [-1.1921e-07, -5.9605e-08,  0.0000e+00],\n",
      "        [ 1.1921e-07,  2.9802e-08,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.9605e-08,  0.0000e+00],\n",
      "        [-2.9802e-08,  8.9407e-08,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.9605e-08,  5.9605e-08,  2.9802e-08],\n",
      "        [ 1.1921e-07,  2.9802e-08,  2.9802e-08],\n",
      "        [ 1.1921e-07, -5.9605e-08,  1.1921e-07],\n",
      "        [ 5.9605e-08, -5.9605e-08,  5.9605e-08],\n",
      "        [ 5.9605e-08,  0.0000e+00, -4.4703e-08]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trans_inv = labels['trans_inv'].cuda()\n",
    "intrinsic_param = labels['intrinsic_param'].cuda()\n",
    "root = labels['joint_root'].cuda()\n",
    "depth_factor = labels['depth_factor'].cuda()\n",
    "\n",
    "\n",
    "cam_jts = m.uvd_to_cam(uvd_jts=labels['target_uvd_29'].reshape(-1, 29, 3).cuda(), \n",
    "             trans_inv=trans_inv, \n",
    "             intrinsic_param=intrinsic_param, \n",
    "             joint_root=root, \n",
    "             depth_factor=depth_factor)\n",
    "\n",
    "\n",
    "inverted_uvd_29 = m.cam_to_uvd(cam_jts.reshape(-1, 29, 3), \n",
    "             trans_inv=trans_inv, \n",
    "             intrinsic_param=intrinsic_param, \n",
    "             joint_root=root, \n",
    "             depth_factor=depth_factor)\n",
    "\n",
    "\n",
    "print(labels['target_uvd_29'].reshape(-1, 29, 3)[1])\n",
    "print(inverted_uvd_29[1])\n",
    "\n",
    "\n",
    "print(inverted_uvd_29[1] - labels['target_uvd_29'].reshape(-1, 29, 3)[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "836a0201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3593, device='cuda:0')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_uvd_29[:,:24].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6fc3c240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3015)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_xyz_24'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "91586fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3015, device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_jts[:,:24].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7502c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19fd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74097585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCBlock(\n",
       "  (forward_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (backward_projection): Linear(in_features=82, out_features=1024, bias=True)\n",
       "  (fc_layers): ModuleList(\n",
       "    (0): Linear(in_features=82, out_features=1024, bias=True)\n",
       "    (1): Dropout(p=0.01, inplace=False)\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (relu_layers): ModuleList(\n",
       "    (0): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (1): Identity()\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.protores_model.net.encoder.blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a45ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219470c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0fcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7b5d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.distributed as dist\n",
    "\n",
    "# dist.init_process_group(backend='nccl', init_method='tcp://172.17.0.4:23456',\n",
    "#                         world_size=1, rank=0)\n",
    "# torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "145ebc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = builder.build_sppe(cfg.MODEL)\n",
    "\n",
    "# m.load_state_dict(torch.load('./model_files/pretrained/pretrained_res34.pth', map_location='cpu'), strict=False)\n",
    "\n",
    "# m = m.cuda()\n",
    "# m = torch.nn.parallel.DistributedDataParallel(m, device_ids=[0])\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "012ab0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9595389569e94f7aa49922e0136060b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8879.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PA-MPJPE 130.1100616455078\n",
      "MPJPE 289.6127624511719\n"
     ]
    }
   ],
   "source": [
    "from deeppose.collections.common.utils.geometry.metric_utils import calc_mpjpe\n",
    "from deeppose.collections.common.utils.geometry.metric_utils import calc_pampjpe\n",
    "\n",
    "class MPJPE():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.accumulated = 0.0\n",
    "        self.count = 0.0\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, align_inds=[0]):\n",
    "        assert preds.shape == target.shape\n",
    "        assert preds.dim() == 3\n",
    "        self.accumulated += torch.sum(calc_mpjpe(preds, target, align_inds)).item() \n",
    "        self.count += target.shape[0]\n",
    "\n",
    "    def compute(self):\n",
    "        return (self.accumulated / self.count)\n",
    "\n",
    "class PA_MPJPE():\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.accumulated = 0.0\n",
    "        self.count = 0.0\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        assert preds.shape == target.shape\n",
    "        assert preds.dim() == 3\n",
    "        self.accumulated += torch.sum(calc_pampjpe(preds, target)).item() \n",
    "        self.count += target.shape[0]\n",
    "\n",
    "    def compute(self):\n",
    "        return (self.accumulated / self.count)\n",
    "\n",
    "pampjpe = PA_MPJPE()\n",
    "mpjpe = MPJPE()\n",
    "pampjpe.reset()\n",
    "mpjpe.reset()\n",
    "\n",
    "with torch.no_grad():\n",
    "    mpjpe_np = []\n",
    "    for batch in tqdm(gt_val_loader):\n",
    "\n",
    "        inps, labels, img_ids, bboxes = batch\n",
    "\n",
    "        trans_inv = labels['trans_inv'].cuda()\n",
    "        intrinsic_param = labels['intrinsic_param'].cuda()\n",
    "        root = labels['joint_root'].cuda()\n",
    "        depth_factor = labels['depth_factor'].cuda()\n",
    "\n",
    "        target_xyz_17 = labels['target_xyz_17'].reshape(-1, 17, 3)\n",
    "        target_xyz_17 = target_xyz_17 - target_xyz_17[:,[gt_val_dataset_3dpw.root_idx_17]]\n",
    "        target_xyz_17 = target_xyz_17[:, gt_val_dataset_3dpw.EVAL_JOINTS]\n",
    "\n",
    "        output_protores = m(inps.cuda(), trans_inv, intrinsic_param, root, depth_factor, None, ik_option='protores')\n",
    "#         output_protores = m(inps.cuda(), trans_inv, intrinsic_param, root, depth_factor, None)\n",
    "\n",
    "        pred_pos = output_protores.pred_xyz_jts_17.reshape(-1, 17, 3)\n",
    "        pred_pos = pred_pos - pred_pos[:,[gt_val_dataset_3dpw.root_idx_17]]\n",
    "        pred_pos = pred_pos[:, gt_val_dataset_3dpw.EVAL_JOINTS].cpu()\n",
    "        \n",
    "        pred_pos = torch.tensor(pred_pos.cpu().numpy())\n",
    "        target_xyz_17 = torch.tensor(target_xyz_17.cpu().numpy())\n",
    "\n",
    "        pampjpe.update(preds=pred_pos, target=target_xyz_17)\n",
    "        # in EVAL_JOINTS 2,3 are left and right hip\n",
    "        mpjpe.update(preds=pred_pos, target=target_xyz_17, align_inds=[2,3])\n",
    "\n",
    "\n",
    "#         joint_relative_17 = labels['labels']['joint_relative_17']\n",
    "#         joint_relative_17 = joint_relative_17 - joint_relative_17[:,[gt_val_dataset_3dpw.root_idx_17]]\n",
    "#         joint_relative_17 = joint_relative_17[:, gt_val_dataset_3dpw.EVAL_JOINTS]\n",
    "\n",
    "#         mpjpe_np.append(np.sqrt(np.sum((joint_relative_17.detach().numpy() - 2*pred_pos.detach().numpy())**2, 2)))\n",
    "        \n",
    "        break\n",
    "    \n",
    "print(\"PA-MPJPE\", pampjpe.compute())\n",
    "print(\"MPJPE\", mpjpe.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "946cbe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2335,  0.8106,  0.3826],\n",
       "        [-0.1847,  0.4151,  0.1586],\n",
       "        [-0.1222, -0.0547,  0.0952],\n",
       "        [ 0.1213,  0.0553, -0.0927],\n",
       "        [ 0.0380,  0.4825,  0.0999],\n",
       "        [ 0.0078,  0.8674,  0.3304],\n",
       "        [-0.2374,  0.0041,  0.1032],\n",
       "        [-0.1573, -0.2497,  0.0900],\n",
       "        [ 0.0024, -0.4638, -0.0500],\n",
       "        [ 0.1851, -0.3586, -0.2624],\n",
       "        [ 0.1386, -0.0693, -0.3049],\n",
       "        [ 0.0176,  0.1608, -0.2573],\n",
       "        [ 0.1008, -0.4632, -0.1786],\n",
       "        [ 0.1612, -0.6418, -0.2315]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_relative_17 = labels['labels']['joint_relative_17']\n",
    "joint_relative_17 = joint_relative_17 - joint_relative_17[:,[gt_val_dataset_3dpw.root_idx_17]]\n",
    "joint_relative_17 = joint_relative_17[:, gt_val_dataset_3dpw.EVAL_JOINTS]\n",
    "joint_relative_17[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a274e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2335,  0.8106,  0.3826],\n",
       "        [-0.1847,  0.4151,  0.1586],\n",
       "        [-0.1222, -0.0547,  0.0952],\n",
       "        [ 0.1213,  0.0553, -0.0927],\n",
       "        [ 0.0380,  0.4825,  0.0999],\n",
       "        [ 0.0078,  0.8674,  0.3304],\n",
       "        [-0.2374,  0.0041,  0.1032],\n",
       "        [-0.1573, -0.2497,  0.0900],\n",
       "        [ 0.0024, -0.4638, -0.0500],\n",
       "        [ 0.1851, -0.3586, -0.2624],\n",
       "        [ 0.1386, -0.0693, -0.3049],\n",
       "        [ 0.0176,  0.1608, -0.2573],\n",
       "        [ 0.1008, -0.4632, -0.1786],\n",
       "        [ 0.1612, -0.6418, -0.2315]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_xyz_17[0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e11ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b5993e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.66204190254211"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.concatenate(mpjpe_np)) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef7a3e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpt_all_pred = {}\n",
    "for r in range(4):\n",
    "    with open(os.path.join('exp', f'pw3d_test_gt_kpt_rank_{r}.pkl'), 'rb') as fid:\n",
    "        kpt_pred = pk.load(fid)\n",
    "        kpt_all_pred.update(kpt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68bba7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample =  5075 # 5494 #\n",
    "\n",
    "with open(os.path.join('exp', f'test_gt_kpt_debug_{sample}.pkl'), 'rb') as fid: \n",
    "    kpt_debug = pk.load(fid)\n",
    "# kpt_debug[5075].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75543d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pred_shape': tensor([-2.9585e-01,  5.8200e-01,  2.8378e-01,  6.6612e-01,  3.7148e-01,\n",
       "          1.7889e-01, -5.4302e-01, -3.8432e-04,  1.4790e+00,  5.1426e-01]),\n",
       " 'pred_theta_mats': tensor([-0.0559,  0.9331,  0.1232, -0.3331,  0.9977,  0.0500,  0.0382, -0.0238,\n",
       "          0.9994, -0.0091, -0.0299, -0.0137,  0.9929,  0.1178,  0.0164,  0.0082,\n",
       "          0.9999,  0.0089,  0.0033, -0.0080,  0.9977,  0.0519, -0.0281, -0.0345,\n",
       "          0.9978, -0.0652, -0.0064, -0.0095,  0.9780, -0.1690,  0.1171,  0.0358,\n",
       "          0.9512,  0.0673,  0.2528,  0.1639,  0.9971,  0.0632, -0.0419, -0.0021,\n",
       "          0.9975, -0.0417,  0.0418,  0.0382,  0.9985, -0.0410, -0.0171, -0.0304,\n",
       "          0.9979, -0.0393, -0.0517,  0.0035,  0.9788,  0.0229, -0.1723, -0.1088,\n",
       "          0.9905, -0.0046,  0.0896,  0.1039,  0.9995, -0.0284, -0.0057, -0.0085,\n",
       "          0.8558,  0.0523, -0.2515, -0.4491,  0.8604,  0.0576,  0.0488,  0.5040,\n",
       "          0.9850,  0.1264, -0.0948, -0.0700,  0.9839,  0.0457,  0.1165,  0.1277,\n",
       "          0.9971, -0.0275, -0.0527,  0.0481,  0.9951, -0.0465,  0.0764, -0.0412,\n",
       "          0.9946, -0.0494, -0.0274, -0.0871,  0.9947, -0.0425,  0.0298,  0.0891]),\n",
       " 'pred_phi': tensor([[ 9.9120e-01, -6.6428e-02],\n",
       "         [ 9.9297e-01,  6.1375e-02],\n",
       "         [ 9.9761e-01,  4.1950e-02],\n",
       "         [ 9.6719e-01, -5.1930e-03],\n",
       "         [ 9.6984e-01,  6.5538e-02],\n",
       "         [ 9.9774e-01, -2.4470e-02],\n",
       "         [ 9.9032e-01, -8.7762e-02],\n",
       "         [ 9.8326e-01,  1.0681e-01],\n",
       "         [ 9.9796e-01,  1.1286e-02],\n",
       "         [ 1.0000e+00, -1.5013e-05],\n",
       "         [ 1.0000e+00, -1.5015e-05],\n",
       "         [ 9.7849e-01, -8.0331e-02],\n",
       "         [ 9.8541e-01, -5.3918e-02],\n",
       "         [ 9.8573e-01,  4.6945e-02],\n",
       "         [ 1.0001e+00, -1.5015e-05],\n",
       "         [ 9.3900e-01,  2.4937e-01],\n",
       "         [ 9.3856e-01, -2.2062e-01],\n",
       "         [ 8.8974e-01,  2.2616e-01],\n",
       "         [ 9.1365e-01, -8.5374e-02],\n",
       "         [ 9.3649e-01, -5.5221e-02],\n",
       "         [ 9.3339e-01,  8.4366e-02],\n",
       "         [ 9.9998e-01, -1.5014e-05],\n",
       "         [ 1.0001e+00, -1.5016e-05]]),\n",
       " 'pred_delta_shape': tensor([-0.0967, -0.0043, -0.1493, -0.0703,  0.0376,  0.0748, -0.0400, -0.0013,\n",
       "          0.2045,  0.0218]),\n",
       " 'pred_leaf': tensor([[ 0.1945, -0.0081,  0.0082,  0.0075],\n",
       "         [-0.0770,  0.0032,  0.0013,  0.0023],\n",
       "         [ 0.1601, -0.0045, -0.0009, -0.0014],\n",
       "         [-0.3546,  0.0176,  0.0098,  0.0311],\n",
       "         [ 0.1659, -0.0071,  0.0050,  0.0149]]),\n",
       " 'pred_uvd_jts': tensor([ 6.9621e-03, -5.5754e-02, -1.9670e-06,  2.0023e-02, -1.0632e-02,\n",
       "         -6.1068e-03, -1.6478e-02, -2.0617e-02,  3.0473e-02,  1.9100e-02,\n",
       "         -1.0016e-01, -4.2338e-03,  1.1626e-02,  1.5588e-01,  4.2153e-02,\n",
       "         -5.6293e-02,  1.3937e-01,  8.4089e-02,  2.0375e-02, -1.6900e-01,\n",
       "         -2.8786e-02,  2.7288e-03,  2.9187e-01,  1.2621e-01, -5.7017e-02,\n",
       "          2.7287e-01,  1.5004e-01,  1.3023e-02, -1.9221e-01, -4.6318e-02,\n",
       "         -1.8090e-02,  3.2581e-01,  7.6280e-02, -7.1977e-02,  2.9565e-01,\n",
       "          1.2834e-01,  2.7912e-02, -2.8814e-01, -6.5983e-02,  4.7842e-02,\n",
       "         -2.4277e-01, -7.9609e-02,  5.7235e-03, -2.5517e-01, -2.8290e-02,\n",
       "          7.9930e-03, -3.3061e-01, -9.5525e-02,  6.2427e-02, -2.3766e-01,\n",
       "         -1.1260e-01, -1.9300e-02, -2.6712e-01, -5.6652e-03,  3.7197e-02,\n",
       "         -8.8760e-02, -1.1431e-01, -3.6207e-02, -1.4397e-01,  7.2827e-02,\n",
       "         -1.8894e-02,  2.9303e-02, -1.0884e-01, -5.4791e-02, -1.6600e-02,\n",
       "          1.0430e-01, -3.4500e-02,  6.9508e-02, -1.0522e-01, -5.9854e-02,\n",
       "          1.6968e-02,  1.1017e-01]),\n",
       " 'pred_xyz_jts_24': tensor([ 0.0000,  0.0000,  0.0000,  0.0150,  0.0472, -0.0061, -0.0315,  0.0398,\n",
       "          0.0305,  0.0137, -0.0470, -0.0042, -0.0031,  0.2346,  0.0422, -0.0887,\n",
       "          0.2265,  0.0841,  0.0195, -0.1182, -0.0288, -0.0297,  0.4162,  0.1262,\n",
       "         -0.1065,  0.4026,  0.1500,  0.0152, -0.1408, -0.0463, -0.0433,  0.4355,\n",
       "          0.0763, -0.1186,  0.4215,  0.1283,  0.0338, -0.2347, -0.0660,  0.0559,\n",
       "         -0.1878, -0.0796,  0.0042, -0.2071, -0.0283,  0.0197, -0.2708, -0.0955,\n",
       "          0.0749, -0.1788, -0.1126, -0.0266, -0.2228, -0.0057,  0.0511, -0.0373,\n",
       "         -0.1143, -0.0631, -0.0957,  0.0728, -0.0035,  0.0755, -0.1088, -0.0921,\n",
       "          0.0508,  0.1043, -0.0193,  0.1145, -0.1052, -0.0995,  0.0903,  0.1102]),\n",
       " 'pred_xyz_jts_24_struct': tensor([ 0.0000,  0.0000,  0.0000,  0.0197,  0.0523, -0.0074, -0.0302,  0.0344,\n",
       "          0.0311,  0.0157, -0.0518, -0.0012,  0.0026,  0.2300,  0.0384, -0.0835,\n",
       "          0.2086,  0.0811,  0.0194, -0.1163, -0.0280, -0.0232,  0.4061,  0.1199,\n",
       "         -0.1019,  0.3910,  0.1494,  0.0154, -0.1396, -0.0454, -0.0394,  0.4290,\n",
       "          0.0605, -0.1274,  0.4307,  0.1039,  0.0346, -0.2437, -0.0677,  0.0570,\n",
       "         -0.1879, -0.0799,  0.0045, -0.2090, -0.0279,  0.0192, -0.2715, -0.0963,\n",
       "          0.0798, -0.1771, -0.1194, -0.0319, -0.2275, -0.0012,  0.0583, -0.0492,\n",
       "         -0.1209, -0.0616, -0.1238,  0.0629,  0.0048,  0.0611, -0.1156, -0.0855,\n",
       "         -0.0036,  0.0887, -0.0107,  0.0995, -0.1120, -0.0930,  0.0364,  0.0946]),\n",
       " 'pred_xyz_jts_17': tensor([ 0.0000,  0.0000,  0.0000,  0.0524,  0.0223, -0.0385,  0.0041,  0.2222,\n",
       "          0.0268, -0.0165,  0.4006,  0.1221, -0.0524, -0.0219,  0.0389, -0.0839,\n",
       "          0.1891,  0.0691, -0.1018,  0.3750,  0.1561,  0.0234, -0.1207, -0.0249,\n",
       "          0.0247, -0.2304, -0.0733,  0.0055, -0.2684, -0.1113,  0.0307, -0.3179,\n",
       "         -0.1076,  0.0707, -0.1847, -0.1123,  0.0461, -0.0495, -0.1421, -0.0052,\n",
       "          0.0638, -0.1223, -0.0222, -0.2251, -0.0155, -0.0819, -0.1229,  0.0584,\n",
       "         -0.0968, -0.0014,  0.0707]),\n",
       " 'pred_vertices': tensor([[ 0.0301, -0.6386, -0.2982],\n",
       "         [ 0.0172, -0.6274, -0.2963],\n",
       "         [ 0.0295, -0.6196, -0.2973],\n",
       "         ...,\n",
       "         [ 0.0139, -0.6180, -0.1426],\n",
       "         [ 0.0125, -0.6195, -0.1437],\n",
       "         [ 0.0086, -0.6184, -0.1429]]),\n",
       " 'maxvals': tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpt_debug[sample]['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3fd6908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3819,  0.5224,  0.2994,  0.6081,  0.1764,  0.2996, -0.5099,  0.0025,\n",
       "         1.4406,  0.6506], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_protores.pred_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dee3b33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput(pred_shape=tensor([[-0.3819,  0.5224,  0.2994,  0.6081,  0.1764,  0.2996, -0.5099,  0.0025,\n",
       "          1.4406,  0.6506]], device='cuda:0'), pred_theta_mats=tensor([[-5.8600e-02,  9.5726e-01,  8.5865e-02, -2.6989e-01,  9.9550e-01,\n",
       "          3.7797e-02,  3.4101e-02, -7.9967e-02,  9.9901e-01, -1.2172e-02,\n",
       "         -2.9448e-02, -3.1122e-02,  9.9606e-01,  7.3250e-02,  2.0539e-02,\n",
       "         -4.5588e-02,  9.9916e-01,  3.4977e-02,  9.6067e-03,  1.8973e-02,\n",
       "          9.9671e-01,  6.3509e-02, -4.2073e-02, -2.7749e-02,  9.9698e-01,\n",
       "         -1.7561e-02, -4.3282e-02,  6.2047e-02,  9.7923e-01, -1.9606e-01,\n",
       "          5.0244e-02,  1.2075e-02,  9.5746e-01, -2.0305e-02,  2.5121e-01,\n",
       "          1.4053e-01,  9.9812e-01,  4.0645e-02, -2.4717e-02, -3.8578e-02,\n",
       "          9.9757e-01, -4.5395e-02,  4.0220e-02,  3.4324e-02,  9.9866e-01,\n",
       "         -3.4833e-02, -2.8368e-02, -2.5734e-02,  9.9571e-01, -4.7511e-02,\n",
       "         -7.7186e-02,  1.8512e-02,  9.6726e-01,  2.2590e-02, -2.0398e-01,\n",
       "         -1.4930e-01,  9.7892e-01, -6.6771e-03,  1.2604e-01,  1.6059e-01,\n",
       "          9.9897e-01,  2.1476e-02,  1.3690e-02, -3.7632e-02,  8.6343e-01,\n",
       "          4.4900e-02, -2.4456e-01, -4.3893e-01,  8.9207e-01,  5.5857e-02,\n",
       "          4.6116e-02,  4.4606e-01,  9.8580e-01,  1.1497e-01, -4.9381e-02,\n",
       "         -1.1202e-01,  9.3161e-01,  3.4818e-02,  2.4093e-01,  2.6988e-01,\n",
       "          9.8278e-01,  4.4807e-04, -4.3021e-02,  1.7967e-01,  9.9568e-01,\n",
       "         -3.4935e-02, -2.9699e-03, -8.5956e-02,  9.9458e-01, -4.7916e-02,\n",
       "         -2.6941e-02, -8.8308e-02,  9.9783e-01, -4.8855e-02,  3.5752e-02,\n",
       "          2.5903e-02]], device='cuda:0'), pred_phi=tensor([[[ 9.9065e-01, -5.9878e-02],\n",
       "         [ 9.9304e-01,  6.1689e-02],\n",
       "         [ 9.9682e-01,  4.6072e-02],\n",
       "         [ 9.6149e-01, -2.4644e-02],\n",
       "         [ 9.6238e-01,  9.1519e-02],\n",
       "         [ 9.9771e-01, -2.4458e-02],\n",
       "         [ 9.9049e-01, -8.2245e-02],\n",
       "         [ 9.8200e-01,  9.1079e-02],\n",
       "         [ 9.9806e-01,  1.2472e-02],\n",
       "         [ 9.9984e-01, -2.2985e-05],\n",
       "         [ 1.0000e+00, -2.2987e-05],\n",
       "         [ 9.7413e-01, -1.0218e-01],\n",
       "         [ 9.8094e-01, -6.9724e-02],\n",
       "         [ 9.8228e-01,  6.3601e-02],\n",
       "         [ 9.9999e-01, -2.2983e-05],\n",
       "         [ 9.4015e-01,  2.2750e-01],\n",
       "         [ 9.4112e-01, -1.9886e-01],\n",
       "         [ 8.9208e-01,  2.0826e-01],\n",
       "         [ 9.1691e-01, -6.9623e-02],\n",
       "         [ 9.3818e-01, -4.7890e-02],\n",
       "         [ 9.3391e-01,  8.5407e-02],\n",
       "         [ 1.0001e+00, -2.2987e-05],\n",
       "         [ 1.0000e+00, -2.2987e-05]]], device='cuda:0'), pred_delta_shape=tensor([[-0.1828, -0.0639, -0.1337, -0.1283, -0.1574,  0.1956, -0.0069,  0.0016,\n",
       "          0.1660,  0.1580]], device='cuda:0'), pred_leaf=tensor([[[ 4.0725e-01, -1.8532e-02,  1.6419e-02,  1.4012e-02],\n",
       "         [-1.8194e-01,  6.3458e-03,  5.1681e-03,  4.6882e-03],\n",
       "         [ 2.6618e-02,  5.7223e-04,  3.6477e-04, -1.0027e-03],\n",
       "         [-3.5213e-01,  1.6965e-02,  9.5386e-03,  3.1266e-02],\n",
       "         [-5.3596e-02,  2.6241e-03, -1.9203e-03, -1.3913e-03]]],\n",
       "       device='cuda:0'), pred_uvd_jts=tensor([[ 5.2291e-03, -5.7162e-02, -1.4305e-06,  3.0963e-02, -1.1828e-02,\n",
       "         -6.1263e-03, -1.8856e-02, -2.4330e-02,  2.5649e-02,  1.8935e-02,\n",
       "         -1.0267e-01, -1.1303e-03,  1.1532e-02,  1.6077e-01,  4.8459e-02,\n",
       "         -5.9498e-02,  1.5052e-01,  7.6920e-02,  2.2760e-02, -1.7085e-01,\n",
       "         -2.3911e-02,  2.1907e-03,  2.9210e-01,  1.3894e-01, -5.5068e-02,\n",
       "          2.7901e-01,  1.4084e-01,  1.3848e-02, -1.9401e-01, -4.1264e-02,\n",
       "         -1.9242e-02,  3.2617e-01,  8.7105e-02, -7.0673e-02,  3.0284e-01,\n",
       "          1.1287e-01,  2.9876e-02, -2.8835e-01, -5.5968e-02,  5.1532e-02,\n",
       "         -2.4362e-01, -6.9211e-02,  2.6577e-03, -2.5628e-01, -2.3381e-02,\n",
       "          1.1264e-02, -3.3185e-01, -8.5392e-02,  6.7539e-02, -2.3609e-01,\n",
       "         -9.9441e-02, -2.7248e-02, -2.6403e-01, -3.7574e-03,  3.6994e-02,\n",
       "         -9.0779e-02, -1.0068e-01, -5.6897e-02, -1.3804e-01,  6.3363e-02,\n",
       "         -1.2914e-02,  2.9576e-02, -8.6861e-02, -5.7782e-02,  6.2255e-03,\n",
       "          3.6740e-02, -2.8042e-02,  6.9735e-02, -9.1459e-02, -5.8281e-02,\n",
       "          3.1527e-02,  3.5240e-02]], device='cuda:0'), pred_xyz_jts_24=tensor([[ 0.0000,  0.0000,  0.0000,  0.0284,  0.0474, -0.0061, -0.0312,  0.0368,\n",
       "          0.0257,  0.0148, -0.0482, -0.0011, -0.0026,  0.2431,  0.0485, -0.0887,\n",
       "          0.2389,  0.0769,  0.0229, -0.1189, -0.0239, -0.0310,  0.4229,  0.1389,\n",
       "         -0.0999,  0.4080,  0.1408,  0.0169, -0.1415, -0.0413, -0.0452,  0.4419,\n",
       "          0.0871, -0.1111,  0.4254,  0.1129,  0.0359, -0.2351, -0.0560,  0.0597,\n",
       "         -0.1885, -0.0692,  0.0019, -0.2074, -0.0234,  0.0227, -0.2726, -0.0854,\n",
       "          0.0798, -0.1774, -0.0994, -0.0336, -0.2183, -0.0038,  0.0505, -0.0375,\n",
       "         -0.1007, -0.0822, -0.0872,  0.0634, -0.0006,  0.0802, -0.0869, -0.0764,\n",
       "          0.0712,  0.0367, -0.0144,  0.1185, -0.0915, -0.0765,  0.0986,  0.0352]],\n",
       "       device='cuda:0'), pred_xyz_jts_24_struct=tensor([[ 0.0000,  0.0000,  0.0000,  0.0248,  0.0502, -0.0049, -0.0310,  0.0370,\n",
       "          0.0267,  0.0113, -0.0527,  0.0009, -0.0028,  0.2249,  0.0438, -0.0809,\n",
       "          0.2128,  0.0713,  0.0226, -0.1168, -0.0231, -0.0301,  0.3973,  0.1305,\n",
       "         -0.0930,  0.3947,  0.1400,  0.0173, -0.1399, -0.0401, -0.0464,  0.4190,\n",
       "          0.0712, -0.1139,  0.4273,  0.0875,  0.0365, -0.2443, -0.0581,  0.0612,\n",
       "         -0.1896, -0.0689,  0.0030, -0.2086, -0.0229,  0.0225, -0.2731, -0.0858,\n",
       "          0.0859, -0.1760, -0.1061, -0.0389, -0.2197, -0.0010,  0.0595, -0.0497,\n",
       "         -0.1072, -0.0780, -0.1144,  0.0530,  0.0111,  0.0614, -0.0941, -0.0735,\n",
       "          0.0082,  0.0324, -0.0027,  0.1000, -0.0988, -0.0737,  0.0490,  0.0301]],\n",
       "       device='cuda:0'), pred_xyz_jts_17=tensor([[ 0.0000,  0.0000,  0.0000,  0.0588,  0.0180, -0.0313,  0.0015,  0.2178,\n",
       "          0.0324, -0.0230,  0.3917,  0.1323, -0.0589, -0.0176,  0.0317, -0.0805,\n",
       "          0.1938,  0.0593, -0.0945,  0.3792,  0.1470,  0.0248, -0.1197, -0.0190,\n",
       "          0.0273, -0.2277, -0.0646,  0.0105, -0.2675, -0.1023,  0.0325, -0.3186,\n",
       "         -0.0997,  0.0775, -0.1835, -0.0995,  0.0506, -0.0478, -0.1288,  0.0025,\n",
       "          0.0660, -0.1031, -0.0270, -0.2193, -0.0129, -0.0963, -0.1099,  0.0459,\n",
       "         -0.0836,  0.0088,  0.0171]], device='cuda:0'), pred_vertices=tensor([[[ 0.0400, -0.6336, -0.2835],\n",
       "         [ 0.0280, -0.6217, -0.2823],\n",
       "         [ 0.0405, -0.6145, -0.2818],\n",
       "         ...,\n",
       "         [ 0.0130, -0.6208, -0.1296],\n",
       "         [ 0.0115, -0.6221, -0.1309],\n",
       "         [ 0.0078, -0.6208, -0.1303]]], device='cuda:0'), maxvals=tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]], device='cuda:0'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_hybrik = m(kpt_debug[sample]['inps'][None].cuda(), \n",
    "                  kpt_debug[sample]['trans_inv'][None].cuda(), \n",
    "                  kpt_debug[sample]['intrinsic_param'][None].cuda(), \n",
    "                  kpt_debug[sample]['joint_root'][None].cuda(), \n",
    "                  kpt_debug[sample]['depth_factor'][None].cuda(), None)\n",
    "\n",
    "output_hybrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a89e8e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelOutput(pred_shape=tensor([[-2.9585e-01,  5.8200e-01,  2.8378e-01,  6.6612e-01,  3.7148e-01,\n",
       "          1.7889e-01, -5.4302e-01, -3.8485e-04,  1.4790e+00,  5.1426e-01]],\n",
       "       grad_fn=<AddBackward0>), pred_theta_mats=tensor([[-0.0559,  0.9332,  0.1232, -0.3331,  0.9977,  0.0500,  0.0382, -0.0238,\n",
       "          0.9994, -0.0091, -0.0299, -0.0137,  0.9929,  0.1178,  0.0164,  0.0082,\n",
       "          0.9999,  0.0089,  0.0033, -0.0080,  0.9977,  0.0519, -0.0281, -0.0345,\n",
       "          0.9978, -0.0652, -0.0064, -0.0095,  0.9780, -0.1690,  0.1171,  0.0358,\n",
       "          0.9512,  0.0673,  0.2528,  0.1639,  0.9971,  0.0632, -0.0419, -0.0021,\n",
       "          0.9975, -0.0417,  0.0418,  0.0382,  0.9985, -0.0410, -0.0171, -0.0304,\n",
       "          0.9979, -0.0393, -0.0517,  0.0035,  0.9788,  0.0229, -0.1723, -0.1088,\n",
       "          0.9905, -0.0046,  0.0896,  0.1039,  0.9995, -0.0284, -0.0057, -0.0085,\n",
       "          0.8558,  0.0523, -0.2515, -0.4491,  0.8604,  0.0576,  0.0488,  0.5040,\n",
       "          0.9850,  0.1264, -0.0948, -0.0700,  0.9839,  0.0457,  0.1165,  0.1277,\n",
       "          0.9971, -0.0275, -0.0527,  0.0481,  0.9951, -0.0465,  0.0764, -0.0412,\n",
       "          0.9946, -0.0494, -0.0274, -0.0871,  0.9947, -0.0425,  0.0298,  0.0891]],\n",
       "       grad_fn=<ReshapeAliasBackward0>), pred_phi=tensor([[[ 9.9120e-01, -6.6428e-02],\n",
       "         [ 9.9297e-01,  6.1375e-02],\n",
       "         [ 9.9761e-01,  4.1950e-02],\n",
       "         [ 9.6719e-01, -5.1929e-03],\n",
       "         [ 9.6984e-01,  6.5538e-02],\n",
       "         [ 9.9774e-01, -2.4470e-02],\n",
       "         [ 9.9032e-01, -8.7762e-02],\n",
       "         [ 9.8326e-01,  1.0681e-01],\n",
       "         [ 9.9796e-01,  1.1286e-02],\n",
       "         [ 1.0000e+00, -1.5013e-05],\n",
       "         [ 1.0000e+00, -1.5015e-05],\n",
       "         [ 9.7849e-01, -8.0331e-02],\n",
       "         [ 9.8541e-01, -5.3918e-02],\n",
       "         [ 9.8573e-01,  4.6944e-02],\n",
       "         [ 1.0001e+00, -1.5015e-05],\n",
       "         [ 9.3900e-01,  2.4937e-01],\n",
       "         [ 9.3856e-01, -2.2062e-01],\n",
       "         [ 8.8974e-01,  2.2616e-01],\n",
       "         [ 9.1365e-01, -8.5374e-02],\n",
       "         [ 9.3649e-01, -5.5221e-02],\n",
       "         [ 9.3339e-01,  8.4367e-02],\n",
       "         [ 9.9998e-01, -1.5014e-05],\n",
       "         [ 1.0001e+00, -1.5015e-05]]], grad_fn=<ReshapeAliasBackward0>), pred_delta_shape=tensor([[-0.0967, -0.0043, -0.1493, -0.0703,  0.0376,  0.0748, -0.0400, -0.0013,\n",
       "          0.2045,  0.0218]], grad_fn=<AddmmBackward0>), pred_leaf=tensor([[[ 0.1945, -0.0081,  0.0082,  0.0075],\n",
       "         [-0.0770,  0.0032,  0.0013,  0.0023],\n",
       "         [ 0.1601, -0.0045, -0.0009, -0.0014],\n",
       "         [-0.3546,  0.0176,  0.0098,  0.0311],\n",
       "         [ 0.1659, -0.0071,  0.0050,  0.0149]]],\n",
       "       grad_fn=<ReshapeAliasBackward0>), pred_uvd_jts=tensor([[ 6.9621e-03, -5.5754e-02, -1.9073e-06,  2.0023e-02, -1.0632e-02,\n",
       "         -6.1068e-03, -1.6479e-02, -2.0617e-02,  3.0473e-02,  1.9100e-02,\n",
       "         -1.0016e-01, -4.2338e-03,  1.1626e-02,  1.5588e-01,  4.2153e-02,\n",
       "         -5.6293e-02,  1.3937e-01,  8.4089e-02,  2.0375e-02, -1.6900e-01,\n",
       "         -2.8786e-02,  2.7287e-03,  2.9187e-01,  1.2621e-01, -5.7017e-02,\n",
       "          2.7287e-01,  1.5004e-01,  1.3023e-02, -1.9221e-01, -4.6318e-02,\n",
       "         -1.8091e-02,  3.2581e-01,  7.6280e-02, -7.1977e-02,  2.9565e-01,\n",
       "          1.2834e-01,  2.7912e-02, -2.8814e-01, -6.5983e-02,  4.7842e-02,\n",
       "         -2.4277e-01, -7.9609e-02,  5.7234e-03, -2.5517e-01, -2.8290e-02,\n",
       "          7.9930e-03, -3.3061e-01, -9.5525e-02,  6.2427e-02, -2.3766e-01,\n",
       "         -1.1260e-01, -1.9300e-02, -2.6712e-01, -5.6654e-03,  3.7197e-02,\n",
       "         -8.8760e-02, -1.1431e-01, -3.6207e-02, -1.4397e-01,  7.2827e-02,\n",
       "         -1.8894e-02,  2.9303e-02, -1.0884e-01, -5.4791e-02, -1.6600e-02,\n",
       "          1.0430e-01, -3.4500e-02,  6.9508e-02, -1.0522e-01, -5.9854e-02,\n",
       "          1.6968e-02,  1.1017e-01]], grad_fn=<ReshapeAliasBackward0>), pred_xyz_jts_24=tensor([[ 0.0000,  0.0000,  0.0000,  0.0150,  0.0472, -0.0061, -0.0315,  0.0398,\n",
       "          0.0305,  0.0137, -0.0470, -0.0042, -0.0031,  0.2346,  0.0422, -0.0887,\n",
       "          0.2265,  0.0841,  0.0195, -0.1182, -0.0288, -0.0297,  0.4162,  0.1262,\n",
       "         -0.1065,  0.4026,  0.1500,  0.0152, -0.1408, -0.0463, -0.0433,  0.4355,\n",
       "          0.0763, -0.1186,  0.4215,  0.1283,  0.0338, -0.2347, -0.0660,  0.0559,\n",
       "         -0.1878, -0.0796,  0.0042, -0.2071, -0.0283,  0.0197, -0.2708, -0.0955,\n",
       "          0.0749, -0.1788, -0.1126, -0.0266, -0.2228, -0.0057,  0.0511, -0.0373,\n",
       "         -0.1143, -0.0631, -0.0957,  0.0728, -0.0035,  0.0755, -0.1088, -0.0921,\n",
       "          0.0508,  0.1043, -0.0193,  0.1145, -0.1052, -0.0995,  0.0903,  0.1102]],\n",
       "       grad_fn=<ReshapeAliasBackward0>), pred_xyz_jts_24_struct=tensor([[ 0.0000,  0.0000,  0.0000,  0.0197,  0.0523, -0.0074, -0.0302,  0.0344,\n",
       "          0.0311,  0.0157, -0.0518, -0.0012,  0.0026,  0.2300,  0.0384, -0.0835,\n",
       "          0.2086,  0.0811,  0.0194, -0.1163, -0.0280, -0.0232,  0.4061,  0.1199,\n",
       "         -0.1019,  0.3910,  0.1494,  0.0154, -0.1396, -0.0454, -0.0394,  0.4290,\n",
       "          0.0605, -0.1274,  0.4307,  0.1039,  0.0346, -0.2437, -0.0677,  0.0570,\n",
       "         -0.1879, -0.0799,  0.0045, -0.2090, -0.0279,  0.0192, -0.2715, -0.0963,\n",
       "          0.0798, -0.1771, -0.1194, -0.0319, -0.2275, -0.0012,  0.0583, -0.0492,\n",
       "         -0.1209, -0.0616, -0.1238,  0.0629,  0.0048,  0.0611, -0.1156, -0.0855,\n",
       "         -0.0036,  0.0887, -0.0107,  0.0995, -0.1120, -0.0930,  0.0364,  0.0946]],\n",
       "       grad_fn=<ReshapeAliasBackward0>), pred_xyz_jts_17=tensor([[ 0.0000,  0.0000,  0.0000,  0.0524,  0.0223, -0.0385,  0.0041,  0.2222,\n",
       "          0.0268, -0.0165,  0.4006,  0.1221, -0.0524, -0.0219,  0.0389, -0.0839,\n",
       "          0.1891,  0.0691, -0.1018,  0.3750,  0.1561,  0.0234, -0.1207, -0.0249,\n",
       "          0.0247, -0.2304, -0.0733,  0.0055, -0.2684, -0.1113,  0.0307, -0.3179,\n",
       "         -0.1076,  0.0707, -0.1847, -0.1123,  0.0461, -0.0495, -0.1421, -0.0052,\n",
       "          0.0638, -0.1223, -0.0222, -0.2251, -0.0155, -0.0819, -0.1229,  0.0584,\n",
       "         -0.0968, -0.0014,  0.0707]], grad_fn=<UnsafeViewBackward0>), pred_vertices=tensor([[[ 0.0301, -0.6386, -0.2982],\n",
       "         [ 0.0172, -0.6274, -0.2963],\n",
       "         [ 0.0295, -0.6196, -0.2973],\n",
       "         ...,\n",
       "         [ 0.0139, -0.6180, -0.1426],\n",
       "         [ 0.0125, -0.6195, -0.1437],\n",
       "         [ 0.0086, -0.6184, -0.1429]]], grad_fn=<SubBackward0>), maxvals=tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_m_debug = kpt_debug[sample]['model'](kpt_debug[sample]['inps'][None], \n",
    "                                            kpt_debug[sample]['trans_inv'][None], \n",
    "                                            kpt_debug[sample]['intrinsic_param'][None], \n",
    "                                            kpt_debug[sample]['joint_root'][None], \n",
    "                                            kpt_debug[sample]['depth_factor'][None], None)\n",
    "\n",
    "output_m_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01b73531",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_debug = kpt_debug[sample]['model']\n",
    "\n",
    "m_parameters = dict(m.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d07394b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in m_debug.named_parameters():\n",
    "    \n",
    "#     print(\"debug model\", k, v)\n",
    "    \n",
    "#     print(\"notebook model\", k, m_parameters[k])\n",
    "    \n",
    "    if not torch.isclose(v.cpu(), m_parameters[k].cpu(), 1e-10).all():\n",
    "        print(\"mismatching parameters\", k)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7dee6faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Simple3DPoseBaseSMPL24(\n",
       "  (preact): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (deconv_layers): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (final_layer): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (smpl): SMPL_layer()\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (decshape): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (decphi): Linear(in_features=1024, out_features=46, bias=True)\n",
       "  (decleaf): Linear(in_features=1024, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5c48385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Simple3DPoseBaseSMPL24(\n",
       "  (preact): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (deconv_layers): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (final_layer): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (smpl): SMPL_layer()\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (drop1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (drop2): Dropout(p=0.5, inplace=False)\n",
       "  (decshape): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (decphi): Linear(in_features=1024, out_features=46, bias=True)\n",
       "  (decleaf): Linear(in_features=1024, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46dc7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc1aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7f5ac38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1213,  0.0553, -0.0927],\n",
       "         [ 0.0380,  0.4825,  0.0999],\n",
       "         ...,\n",
       "         [ 0.0024, -0.4638, -0.0500],\n",
       "         [-0.1573, -0.2497,  0.0900],\n",
       "         [-0.2374,  0.0041,  0.1032]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0729,  0.0180,  0.1431],\n",
       "         [ 0.0801,  0.4899,  0.0608],\n",
       "         ...,\n",
       "         [-0.1009, -0.4755, -0.0663],\n",
       "         [-0.1768, -0.2231, -0.1932],\n",
       "         [-0.1101,  0.0257, -0.2313]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1415,  0.0070, -0.0117],\n",
       "         [ 0.1294,  0.4215,  0.0527],\n",
       "         ...,\n",
       "         [-0.1575, -0.3982, -0.0811],\n",
       "         [-0.3217, -0.2232, -0.1669],\n",
       "         [-0.2708, -0.2335, -0.3769]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.1128,  0.0264, -0.1118],\n",
       "         [ 0.0210,  0.4939, -0.1126],\n",
       "         ...,\n",
       "         [-0.0645, -0.4678,  0.0639],\n",
       "         [-0.1362, -0.2364,  0.2465],\n",
       "         [-0.1622,  0.0199,  0.2072]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.1246, -0.0534,  0.0914],\n",
       "         [-0.2398,  0.3827,  0.2148],\n",
       "         ...,\n",
       "         [ 0.4193, -0.1468,  0.0895],\n",
       "         [ 0.5485,  0.0920,  0.1387],\n",
       "         [ 0.6583,  0.2538,  0.3188]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0747,  0.0269, -0.1182],\n",
       "         [ 0.0640,  0.4365, -0.0049],\n",
       "         ...,\n",
       "         [-0.0942, -0.4216,  0.0429],\n",
       "         [-0.2118, -0.2163,  0.1690],\n",
       "         [-0.3054, -0.2674, -0.0153]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_xyz_17'].reshape(-1, 17, 3) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ddf5bc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1168,  0.4053,  0.1913],\n",
       "         [-0.0923,  0.2075,  0.0793],\n",
       "         [-0.0611, -0.0273,  0.0476],\n",
       "         ...,\n",
       "         [ 0.0088,  0.0804, -0.1287],\n",
       "         [ 0.0504, -0.2316, -0.0893],\n",
       "         [ 0.0806, -0.3209, -0.1158]],\n",
       "\n",
       "        [[-0.0157,  0.4538, -0.1089],\n",
       "         [-0.0032,  0.2265, -0.0806],\n",
       "         [-0.0368, -0.0082, -0.0726],\n",
       "         ...,\n",
       "         [ 0.0846,  0.0307,  0.1186],\n",
       "         [-0.0109, -0.2569,  0.0323],\n",
       "         [ 0.0026, -0.3495,  0.0450]],\n",
       "\n",
       "        [[-0.0869,  0.3606,  0.1548],\n",
       "         [-0.0801,  0.1995,  0.0386],\n",
       "         [-0.0711, -0.0026,  0.0052],\n",
       "         ...,\n",
       "         [ 0.0662, -0.1244, -0.2160],\n",
       "         [-0.0099, -0.2201, -0.0560],\n",
       "         [-0.0191, -0.2894, -0.1120]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0046,  0.4385,  0.1293],\n",
       "         [-0.0448,  0.2257,  0.0573],\n",
       "         [-0.0573, -0.0129,  0.0571],\n",
       "         ...,\n",
       "         [ 0.1182,  0.0288, -0.1225],\n",
       "         [ 0.0109, -0.2528, -0.0352],\n",
       "         [-0.0239, -0.3314, -0.0868]],\n",
       "\n",
       "        [[ 0.0407,  0.4281,  0.1694],\n",
       "         [ 0.0519,  0.2184,  0.0815],\n",
       "         [ 0.0626,  0.0269, -0.0463],\n",
       "         ...,\n",
       "         [-0.0131,  0.0491,  0.1442],\n",
       "         [ 0.1782, -0.1276,  0.0929],\n",
       "         [ 0.2498, -0.1679,  0.1204]],\n",
       "\n",
       "        [[ 0.0367,  0.3724,  0.1515],\n",
       "         [-0.0272,  0.1969,  0.0790],\n",
       "         [-0.0378, -0.0131,  0.0595],\n",
       "         ...,\n",
       "         [-0.1655, -0.0526, -0.0997],\n",
       "         [-0.0341, -0.2195, -0.0512],\n",
       "         [-0.0945, -0.2859, -0.0700]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_xyz_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45697b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31e7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01e39118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 14, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(gt_val_loader))\n",
    "inps, labels, _, bboxes = batch\n",
    "\n",
    "trans_inv = labels['trans_inv']\n",
    "intrinsic_param = labels['intrinsic_param']\n",
    "root = labels['joint_root']\n",
    "depth_factor = labels['depth_factor']\n",
    "label_masks_17 = labels['target_weight_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78bf5cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4230245c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0657,  0.0111, -0.0457],\n",
       "        [ 0.0448,  0.2424,  0.0106],\n",
       "        [ 0.0545,  0.4565,  0.0798],\n",
       "        [-0.0665, -0.0102,  0.0467],\n",
       "        [-0.0323,  0.2259,  0.0586],\n",
       "        [-0.0079,  0.4472,  0.1175],\n",
       "        [ 0.0151, -0.1267,  0.0030],\n",
       "        [ 0.0230, -0.2513, -0.0027],\n",
       "        [ 0.0116, -0.2971, -0.0334],\n",
       "        [ 0.0244, -0.3511, -0.0179],\n",
       "        [ 0.0818, -0.2156, -0.0450],\n",
       "        [ 0.1028, -0.0706, -0.0604],\n",
       "        [ 0.0825,  0.0588, -0.0523],\n",
       "        [-0.0357, -0.2264,  0.0481],\n",
       "        [-0.0732, -0.0856,  0.0773],\n",
       "        [-0.0814,  0.0464,  0.0641]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_xyz_17 = labels['target_xyz_17'][batch_idx].reshape(17, 3)\n",
    "target_xyz_17 - target_xyz_17[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e92af0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hybrik = m(inps, trans_inv, intrinsic_param, root, depth_factor, None, ik_option='hybrik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c738d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_protores = m(inps, trans_inv, intrinsic_param, root, depth_factor, None, ik_option='protores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0090b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_device(input, device):\n",
    "    output = dict()\n",
    "    for k, v in input.items():\n",
    "        output[k] = v.to(device)\n",
    "    return output\n",
    "\n",
    "def pack_data(betas, position_data, position_id, rotation_data=None, rotation_id=None):\n",
    "    \n",
    "    input_data = {'betas': betas,\n",
    "                  'gender': 2 * torch.ones(len(betas), 1).to(betas).to(dtype=int),\n",
    "                  'position_data': position_data,\n",
    "                  'position_weight': torch.ones(len(betas), position_id.shape[0]).to(betas),\n",
    "                  'position_tolerance': torch.zeros(len(betas), position_id.shape[0]).to(betas),\n",
    "                  'position_id': position_id[None].repeat(len(betas), 1).to(betas).to(dtype=int),\n",
    "                  'rotation_data': torch.empty(len(betas), 0, 6).to(betas),\n",
    "                  'rotation_weight': torch.empty(len(betas), 0).to(betas),\n",
    "                  'rotation_tolerance': torch.empty(len(betas), 0).to(betas),\n",
    "                  'rotation_id': torch.empty(len(betas), 0, dtype=int).to(betas).to(dtype=int),\n",
    "                  'lookat_data': torch.empty(len(betas), 0, 6).to(betas),\n",
    "                  'lookat_weight': torch.empty(len(betas), 0).to(betas),\n",
    "                  'lookat_tolerance': torch.empty(len(betas), 0).to(betas),\n",
    "                  'lookat_id': torch.empty(len(betas), 0, dtype=int).to(betas).to(dtype=int),\n",
    "                 }\n",
    "    \n",
    "    if rotation_data is not None:\n",
    "        input_data['rotation_data'] = rotation_data\n",
    "        input_data['rotation_id'] = rotation_id[None].repeat(len(betas), 1).to(betas).to(dtype=int)\n",
    "        input_data['rotation_weight'] = torch.ones(len(betas), rotation_id.shape[0]).to(betas)\n",
    "        input_data['rotation_tolerance'] = torch.zeros(len(betas), rotation_id.shape[0]).to(betas)\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "def deeppose_fk(input_data, deeppose_net):\n",
    "    input_data = dict_to_device(input_data, device=deeppose_net.device)\n",
    "    \n",
    "    predictions = deeppose_net(input_data)\n",
    "\n",
    "    betas = input_data[\"betas\"]\n",
    "    gender = input_data[\"gender\"]\n",
    "\n",
    "    predicted_root_joint_position = predictions[\"root_joint_position\"]\n",
    "    predicted_joint_rotations = predictions[\"joint_rotations\"]\n",
    "            \n",
    "    # compute rotation matrices\n",
    "    predicted_joint_rotations_mat = rotation_6d_to_matrix(predicted_joint_rotations.view(-1, 6)).view(-1, deeppose_net.nb_joints, 3, 3)\n",
    "    # apply forward kinematics\n",
    "    predicted_joint_rotations_quat = matrix_to_quaternion(predicted_joint_rotations_mat)\n",
    "\n",
    "    predicted_joint_positions_fk, predicted_joint_rotations_fk = deeppose_net.apply_smpl_quat(betas=betas,\n",
    "                                                                                              joint_rotations_quat=predicted_joint_rotations_quat,\n",
    "                                                                                              root_position=predicted_root_joint_position,\n",
    "                                                                                              gender=gender)\n",
    "    joint_rotations_axis_angle = quaternion_to_axis_angle(predicted_joint_rotations_quat)    \n",
    "        \n",
    "    return predicted_joint_positions_fk, predicted_joint_rotations_fk\n",
    "\n",
    "betas = labels['target_beta']\n",
    "# betas = output_protores.pred_shape\n",
    "protores_data = pack_data(betas = betas, \n",
    "                          position_data = 2 * output_protores.pred_xyz_jts_24.type(torch.float32).view(-1, 24, 3), \n",
    "                          position_id = torch.tensor(np.arange(24)).to(output_protores.pred_shape).to(dtype=int)\n",
    "#                                   position_id = torch.tensor([0, 7, 8, 12, 20, 21]).to(params_pred['betas']).to(dtype=int),\n",
    "#                                   rotation_data = params_pred['rotation_data'].view(-1, 6, 6),\n",
    "#                                   rotation_id = torch.tensor([0, 7, 8, 12, 20, 21]).to(params_pred['betas']).to(dtype=int),\n",
    "                         )\n",
    "\n",
    "predicted_joint_positions_fk, predicted_joint_rotations_fk = deeppose_fk(protores_data, m.protores_model)\n",
    "predicted_joint_positions_fk = predicted_joint_positions_fk / 2\n",
    "predicted_joint_positions_fk = predicted_joint_positions_fk - predicted_joint_positions_fk[:, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52c4c9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0333,  0.0519, -0.0082],\n",
       "        [-0.0349,  0.0452,  0.0218],\n",
       "        [ 0.0080, -0.0592,  0.0080],\n",
       "        [ 0.0285,  0.2553, -0.0340],\n",
       "        [-0.0481,  0.2526,  0.0389],\n",
       "        [ 0.0106, -0.1253, -0.0131],\n",
       "        [ 0.0487,  0.4280,  0.0978],\n",
       "        [ 0.0232,  0.4304,  0.1447],\n",
       "        [ 0.0054, -0.1493, -0.0319],\n",
       "        [ 0.0575,  0.4683,  0.0399],\n",
       "        [-0.0288,  0.4612,  0.1058],\n",
       "        [ 0.0165, -0.2642, -0.0289],\n",
       "        [ 0.0516, -0.2121, -0.0412],\n",
       "        [-0.0240, -0.2182, -0.0079],\n",
       "        [ 0.0092, -0.2952, -0.0557],\n",
       "        [ 0.0962, -0.2114, -0.0591],\n",
       "        [-0.0712, -0.2319,  0.0083],\n",
       "        [ 0.1294, -0.0797, -0.0389],\n",
       "        [-0.0855, -0.1182,  0.0797],\n",
       "        [ 0.0870,  0.0397, -0.0685],\n",
       "        [-0.1002,  0.0150,  0.0628],\n",
       "        [ 0.0721,  0.0815, -0.0696],\n",
       "        [-0.0909,  0.0587,  0.0607]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_joint_positions_fk[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d01cbb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0169, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels['target_xyz_24'][batch_idx]-predicted_joint_positions_fk[batch_idx].ravel()).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8061b683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0168, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels['target_xyz_24'][batch_idx]-output_protores.pred_xyz_jts_24_struct[batch_idx]).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a041c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0169, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels['target_xyz_24'][batch_idx]-output_hybrik.pred_xyz_jts_24_struct[batch_idx]).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbe9ed15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0285,  0.0482, -0.0054],\n",
       "        [-0.0330,  0.0449,  0.0172],\n",
       "        [ 0.0126, -0.0526,  0.0054],\n",
       "        [ 0.0457,  0.2470,  0.0150],\n",
       "        [-0.0292,  0.2459,  0.0613],\n",
       "        [ 0.0132, -0.1234, -0.0083],\n",
       "        [ 0.0525,  0.4244,  0.0727],\n",
       "        [ 0.0184,  0.4187,  0.1317],\n",
       "        [ 0.0066, -0.1509, -0.0259],\n",
       "        [ 0.0424,  0.4385,  0.0326],\n",
       "        [-0.0136,  0.4499,  0.1105],\n",
       "        [ 0.0146, -0.2474, -0.0273],\n",
       "        [ 0.0487, -0.2088, -0.0407],\n",
       "        [-0.0187, -0.2121, -0.0071],\n",
       "        [-0.0033, -0.2890, -0.0561],\n",
       "        [ 0.0778, -0.2103, -0.0648],\n",
       "        [-0.0564, -0.2206,  0.0020],\n",
       "        [ 0.1130, -0.0754, -0.0590],\n",
       "        [-0.0799, -0.1054,  0.0623],\n",
       "        [ 0.0808,  0.0360, -0.0627],\n",
       "        [-0.0929,  0.0152,  0.0673],\n",
       "        [ 0.0668,  0.0765, -0.0635],\n",
       "        [-0.0955,  0.0613,  0.0608]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_protores.pred_xyz_jts_24[batch_idx].reshape(24, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed8b2f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0056,  0.0070, -0.0006],\n",
       "        [ 0.0369,  0.0539, -0.0011],\n",
       "        [-0.0241,  0.0478,  0.0222],\n",
       "        [ 0.0101, -0.0471,  0.0011],\n",
       "        [ 0.0517,  0.2368,  0.0168],\n",
       "        [-0.0315,  0.2313,  0.0665],\n",
       "        [ 0.0145, -0.1153, -0.0141],\n",
       "        [ 0.0503,  0.4238,  0.0750],\n",
       "        [ 0.0117,  0.4090,  0.1366],\n",
       "        [ 0.0107, -0.1390, -0.0310],\n",
       "        [ 0.0351,  0.4626,  0.0243],\n",
       "        [-0.0193,  0.4582,  0.1065],\n",
       "        [ 0.0181, -0.2476, -0.0295],\n",
       "        [ 0.0525, -0.1979, -0.0410],\n",
       "        [-0.0172, -0.2024, -0.0085],\n",
       "        [ 0.0090, -0.2760, -0.0601],\n",
       "        [ 0.0940, -0.1979, -0.0629],\n",
       "        [-0.0628, -0.2132,  0.0054],\n",
       "        [ 0.1165, -0.0722, -0.0427],\n",
       "        [-0.0720, -0.1011,  0.0600],\n",
       "        [ 0.0872,  0.0436, -0.0675],\n",
       "        [-0.0973,  0.0209,  0.0605],\n",
       "        [ 0.0746,  0.0825, -0.0742],\n",
       "        [-0.0978,  0.0619,  0.0621]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_protores.pred_xyz_jts_24_struct[batch_idx].reshape(24, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60396728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0223,  0.0494, -0.0156],\n",
       "        [-0.0265,  0.0403,  0.0272],\n",
       "        [ 0.0126, -0.0526,  0.0054],\n",
       "        [ 0.0437,  0.2304,  0.0124],\n",
       "        [-0.0290,  0.2268,  0.0581],\n",
       "        [ 0.0132, -0.1213, -0.0079],\n",
       "        [ 0.0521,  0.4174,  0.0705],\n",
       "        [ 0.0150,  0.4051,  0.1264],\n",
       "        [ 0.0077, -0.1460, -0.0229],\n",
       "        [ 0.0378,  0.4486,  0.0145],\n",
       "        [-0.0188,  0.4581,  0.1076],\n",
       "        [ 0.0143, -0.2545, -0.0300],\n",
       "        [ 0.0487, -0.2041, -0.0389],\n",
       "        [-0.0199, -0.2108, -0.0043],\n",
       "        [-0.0018, -0.2861, -0.0539],\n",
       "        [ 0.0833, -0.2114, -0.0697],\n",
       "        [-0.0665, -0.2233,  0.0038],\n",
       "        [ 0.1108, -0.0854, -0.0598],\n",
       "        [-0.0792, -0.1118,  0.0591],\n",
       "        [ 0.0815,  0.0332, -0.0626],\n",
       "        [-0.0926,  0.0120,  0.0670],\n",
       "        [ 0.0682,  0.0725, -0.0634],\n",
       "        [-0.0950,  0.0527,  0.0619]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_hybrik.pred_xyz_jts_24_struct[batch_idx].reshape(24, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bed8fe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0513,  0.0128, -0.0434],\n",
       "        [ 0.0425,  0.2204,  0.0016],\n",
       "        [ 0.0581,  0.4092,  0.0735],\n",
       "        [-0.0518, -0.0125,  0.0436],\n",
       "        [-0.0365,  0.2060,  0.0487],\n",
       "        [ 0.0111,  0.3862,  0.1311],\n",
       "        [ 0.0102, -0.1281, -0.0050],\n",
       "        [ 0.0057, -0.2463, -0.0397],\n",
       "        [-0.0129, -0.2865, -0.0686],\n",
       "        [-0.0007, -0.3359, -0.0461],\n",
       "        [ 0.0701, -0.2163, -0.0622],\n",
       "        [ 0.1070, -0.0836, -0.0848],\n",
       "        [ 0.0753,  0.0350, -0.0732],\n",
       "        [-0.0520, -0.2255, -0.0014],\n",
       "        [-0.0991, -0.1084,  0.0497],\n",
       "        [-0.0989,  0.0104,  0.0477]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrik_xyz_17 = output_hybrik.pred_xyz_jts_17[batch_idx].reshape(17, 3)\n",
    "hybrik_xyz_17 - hybrik_xyz_17[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15662254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0642,  0.0097, -0.0222],\n",
       "        [ 0.0482,  0.2207,  0.0090],\n",
       "        [ 0.0523,  0.4100,  0.0788],\n",
       "        [-0.0646, -0.0093,  0.0221],\n",
       "        [-0.0411,  0.2049,  0.0550],\n",
       "        [-0.0010,  0.3858,  0.1430],\n",
       "        [ 0.0104, -0.1244, -0.0083],\n",
       "        [ 0.0093, -0.2408, -0.0383],\n",
       "        [-0.0049, -0.2796, -0.0765],\n",
       "        [ 0.0022, -0.3317, -0.0578],\n",
       "        [ 0.0754, -0.2084, -0.0565],\n",
       "        [ 0.1108, -0.0760, -0.0676],\n",
       "        [ 0.0763,  0.0390, -0.0756],\n",
       "        [-0.0527, -0.2204, -0.0014],\n",
       "        [-0.0955, -0.1029,  0.0483],\n",
       "        [-0.1018,  0.0158,  0.0419]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protores_xyz_17 = output_protores.pred_xyz_jts_17[batch_idx].reshape(17, 3)\n",
    "protores_xyz_17 - protores_xyz_17[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3abe191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'target_theta', 'target_theta_weight', 'target_beta', 'target_smpl_weight', 'target_uvd_29', 'target_xyz_24', 'target_weight_29', 'target_weight_24', 'target_xyz_17', 'target_weight_17', 'trans_inv', 'intrinsic_param', 'joint_root', 'depth_factor', 'target_twist', 'target_twist_weight'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bddedb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0657,  0.0111, -0.0457],\n",
       "        [ 0.0448,  0.2424,  0.0106],\n",
       "        [ 0.0545,  0.4565,  0.0798],\n",
       "        [-0.0665, -0.0102,  0.0467],\n",
       "        [-0.0323,  0.2259,  0.0586],\n",
       "        [-0.0079,  0.4472,  0.1175],\n",
       "        [ 0.0151, -0.1267,  0.0030],\n",
       "        [ 0.0230, -0.2513, -0.0027],\n",
       "        [ 0.0116, -0.2971, -0.0334],\n",
       "        [ 0.0244, -0.3511, -0.0179],\n",
       "        [ 0.0818, -0.2156, -0.0450],\n",
       "        [ 0.1028, -0.0706, -0.0604],\n",
       "        [ 0.0825,  0.0588, -0.0523],\n",
       "        [-0.0357, -0.2264,  0.0481],\n",
       "        [-0.0732, -0.0856,  0.0773],\n",
       "        [-0.0814,  0.0464,  0.0641]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_xyz_17 = labels['target_xyz_17'][batch_idx].reshape(17, 3)\n",
    "target_xyz_17 - target_xyz_17[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07a822ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0158, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_xyz_17 - (hybrik_xyz_17-hybrik_xyz_17[0])).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f111e528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0657,  0.0111, -0.0457],\n",
       "        [ 0.0448,  0.2424,  0.0106],\n",
       "        [ 0.0545,  0.4565,  0.0798],\n",
       "        [-0.0665, -0.0102,  0.0467],\n",
       "        [-0.0323,  0.2259,  0.0586],\n",
       "        [-0.0079,  0.4472,  0.1175],\n",
       "        [ 0.0151, -0.1267,  0.0030],\n",
       "        [ 0.0230, -0.2513, -0.0027],\n",
       "        [ 0.0116, -0.2971, -0.0334],\n",
       "        [ 0.0244, -0.3511, -0.0179],\n",
       "        [ 0.0818, -0.2156, -0.0450],\n",
       "        [ 0.1028, -0.0706, -0.0604],\n",
       "        [ 0.0825,  0.0588, -0.0523],\n",
       "        [-0.0357, -0.2264,  0.0481],\n",
       "        [-0.0732, -0.0856,  0.0773],\n",
       "        [-0.0814,  0.0464,  0.0641]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_xyz_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bed54162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0157, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_xyz_17 - (protores_xyz_17-protores_xyz_17[0])).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39422245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.2438, grad_fn=<AddBackward0>),\n",
       " {'loss_tot': tensor(3.2438, grad_fn=<AddBackward0>),\n",
       "  'loss_beta': tensor(1.8465, grad_fn=<MseLossBackward0>),\n",
       "  'loss_theta': tensor(0.0487, grad_fn=<MseLossBackward0>),\n",
       "  'loss_uvd': tensor(1.1440, grad_fn=<DivBackward0>),\n",
       "  'loss_xyz_smpl24': tensor(1.3166, grad_fn=<DivBackward0>),\n",
       "  'loss_xyz_smpl17': tensor(1.2114, grad_fn=<DivBackward0>)})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_protores = criterion(output_protores, labels)\n",
    "loss_protores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07c1a4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.2387, grad_fn=<AddBackward0>),\n",
       " {'loss_tot': tensor(3.2387, grad_fn=<AddBackward0>),\n",
       "  'loss_beta': tensor(1.8493, grad_fn=<MseLossBackward0>),\n",
       "  'loss_theta': tensor(0.0531, grad_fn=<MseLossBackward0>),\n",
       "  'loss_uvd': tensor(1.1440, grad_fn=<DivBackward0>),\n",
       "  'loss_xyz_smpl24': tensor(1.2877, grad_fn=<DivBackward0>),\n",
       "  'loss_xyz_smpl17': tensor(1.1610, grad_fn=<DivBackward0>)})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_hybrik = criterion(output_hybrik, labels)\n",
    "loss_hybrik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bf66bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_coord_accuracy(output_hybrik.pred_xyz_jts_24_struct, labels['target_xyz_24'], labels['target_weight_24'], \n",
    "                    hm_shape, num_joints=24, root_idx=gt_val_loader.dataset.root_idx_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c10629c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_coord_accuracy(predicted_joint_positions_fk.reshape(-1, 72), labels['target_xyz_24'], labels['target_weight_24'], \n",
    "                    hm_shape, num_joints=24, root_idx=gt_val_loader.dataset.root_idx_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f443ec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927083333333334"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_coord_accuracy(output_protores.pred_xyz_jts_24_struct, labels['target_xyz_24'], labels['target_weight_24'], \n",
    "                    hm_shape, num_joints=24, root_idx=gt_val_loader.dataset.root_idx_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb775025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395833333333334"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_coord_accuracy(output_hybrik.pred_xyz_jts_17, labels['target_xyz_17'], label_masks_17, \n",
    "                    hm_shape, num_joints=17, root_idx=gt_val_loader.dataset.root_idx_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "670ec5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_xyz_jts_17_protores = output_protores.pred_xyz_jts_17.reshape(-1, 17, 3)\n",
    "pred_xyz_jts_17_protores = (pred_xyz_jts_17_protores - pred_xyz_jts_17_protores[:,[0]]).reshape(-1, 51)\n",
    "\n",
    "calc_coord_accuracy(pred_xyz_jts_17_protores, labels['target_xyz_17'], label_masks_17, \n",
    "                    hm_shape, num_joints=17, root_idx=gt_val_loader.dataset.root_idx_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8540a31d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-9fa21ddc4b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m calc_coord_accuracy(output_protores.pred_xyz_jts_17 + 0.002, labels['target_xyz_17'], label_masks_17, \n\u001b[0;32m---> 83\u001b[0;31m                     hm_shape, num_joints=17, root_idx=train_loader.dataset.root_idx_17)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "def calc_dist(preds, target, normalize):\n",
    "    \"\"\"Calculate normalized distances\"\"\"\n",
    "    preds = preds.astype(np.float32)\n",
    "    target = target.astype(np.float32)\n",
    "    dists = np.zeros((preds.shape[1], preds.shape[0]))\n",
    "\n",
    "    for n in range(preds.shape[0]):\n",
    "        for c in range(preds.shape[1]):\n",
    "            if target[n, c, 0] > 1 and target[n, c, 1] > 1:\n",
    "                normed_preds = preds[n, c, :] / normalize[n]\n",
    "                normed_targets = target[n, c, :] / normalize[n]\n",
    "                dists[c, n] = np.linalg.norm(normed_preds - normed_targets)\n",
    "            else:\n",
    "                dists[c, n] = -1\n",
    "\n",
    "    return dists\n",
    "\n",
    "def dist_acc(dists, thr=0.5):\n",
    "    \"\"\"Calculate accuracy with given input distance.\"\"\"\n",
    "    dist_cal = np.not_equal(dists, -1)\n",
    "    num_dist_cal = dist_cal.sum()\n",
    "    if num_dist_cal > 0:\n",
    "        return np.less(dists[dist_cal], thr).sum() * 1.0 / num_dist_cal\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def calc_coord_accuracy(pred_jts, labels, label_masks, hm_shape, norm='softmax', num_joints=None, root_idx=None):\n",
    "    \"\"\"Calculate integral coordinates accuracy.\"\"\"\n",
    "    coords = pred_jts.clone().detach().cpu().numpy()\n",
    "    coords = coords.astype(float)\n",
    "    \n",
    "    if num_joints is not None:\n",
    "        coords = coords.reshape(coords.shape[0], num_joints, -1)\n",
    "        labels = labels.reshape(labels.shape[0], num_joints, -1)\n",
    "        label_masks = label_masks.reshape(label_masks.shape[0], num_joints, -1)\n",
    "        coords = coords[:, :, :3].reshape(coords.shape[0], -1)\n",
    "        labels = labels[:, :, :3].reshape(coords.shape[0], -1)\n",
    "        label_masks = label_masks[:, :, :3].reshape(coords.shape[0], -1)\n",
    "    else:\n",
    "        num_joints = coords.shape[1] // 3\n",
    "\n",
    "    hm_width, hm_height, hm_depth = hm_shape\n",
    "    coords = coords.reshape((coords.shape[0], int(coords.shape[1] / 3), 3))\n",
    "\n",
    "    coords[:, :, 0] = (coords[:, :, 0] + 0.5) * hm_width\n",
    "    coords[:, :, 1] = (coords[:, :, 1] + 0.5) * hm_height\n",
    "\n",
    "    labels = labels.clone().cpu().data.numpy().reshape(pred_jts.shape[0], num_joints, 3)\n",
    "    label_masks = label_masks.cpu().data.numpy().reshape(pred_jts.shape[0], num_joints, 3)\n",
    "\n",
    "    labels[:, :, 0] = (labels[:, :, 0] + 0.5) * hm_width\n",
    "    labels[:, :, 1] = (labels[:, :, 1] + 0.5) * hm_height\n",
    "    labels[:, :, 2] = (labels[:, :, 2] + 0.5) * hm_depth\n",
    "\n",
    "    coords[:, :, 2] = (coords[:, :, 2] + 0.5) * hm_depth\n",
    "\n",
    "    if root_idx is not None:\n",
    "        labels = labels - labels[:, root_idx, :][:, None, :]\n",
    "#         coords = coords - coords[:, root_idx, :][:, None, :]\n",
    "\n",
    "    coords = coords * label_masks\n",
    "    labels = labels * label_masks\n",
    "\n",
    "    norm = np.ones((pred_jts.shape[0], 3)) * np.array([hm_width, hm_height, hm_depth]) / 10\n",
    "\n",
    "    dists = calc_dist(coords, labels, norm)\n",
    "\n",
    "    acc = 0\n",
    "    sum_acc = 0\n",
    "    cnt = 0\n",
    "    for i in range(num_joints):\n",
    "        acc = dist_acc(dists[i])\n",
    "        if acc >= 0:\n",
    "            sum_acc += acc\n",
    "            cnt += 1\n",
    "\n",
    "    if cnt > 0:\n",
    "        return sum_acc / cnt\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "calc_coord_accuracy(output_protores.pred_xyz_jts_17 + 0.002, labels['target_xyz_17'], label_masks_17, \n",
    "                    hm_shape, num_joints=17, root_idx=train_loader.dataset.root_idx_17)\n",
    "\n",
    "\n",
    "(target_xyz_17 - protores_xyz_17).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca02794e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0024,  0.0547,  0.0039], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target_xyz_17 - protores_xyz_17).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f54a611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000,  0.0000,  0.0000],\n",
       "        [-0.0643, -0.0033,  0.0291],\n",
       "        [-0.0162,  0.1818,  0.1205],\n",
       "        [-0.0658,  0.3751,  0.1050],\n",
       "        [ 0.0637,  0.0043, -0.0291],\n",
       "        [ 0.0521,  0.2088,  0.0199],\n",
       "        [ 0.0138,  0.4052,  0.0476],\n",
       "        [-0.0165, -0.1137, -0.0377],\n",
       "        [-0.0104, -0.2272, -0.0475],\n",
       "        [-0.0007, -0.2880, -0.0258],\n",
       "        [-0.0153, -0.3349, -0.0543],\n",
       "        [-0.0780, -0.1998, -0.0175],\n",
       "        [-0.1170, -0.0778,  0.0345],\n",
       "        [-0.1022,  0.0191,  0.0970],\n",
       "        [ 0.0532, -0.1934, -0.0734],\n",
       "        [ 0.1090, -0.0653, -0.0529],\n",
       "        [ 0.1409,  0.0374, -0.0040]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_xyz_17'][3].reshape(17,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3a0bb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0566,  0.0636, -0.1009],\n",
       "        [-0.1862,  0.0663, -0.0396],\n",
       "        [-0.0782,  0.1364,  0.3452],\n",
       "        [-0.0554,  0.2945,  0.0454],\n",
       "        [ 0.0724,  0.0606, -0.1614],\n",
       "        [ 0.3270,  0.2154,  0.1008],\n",
       "        [ 0.0306,  0.3036,  0.0253],\n",
       "        [-0.0320, -0.1601, -0.0914],\n",
       "        [-0.0036, -0.3857, -0.0198],\n",
       "        [ 0.0033, -0.4507,  0.0532],\n",
       "        [-0.0118, -0.5521,  0.0151],\n",
       "        [-0.1437, -0.3388,  0.0071],\n",
       "        [-0.2465, -0.1015,  0.0151],\n",
       "        [-0.0841,  0.0471,  0.0119],\n",
       "        [ 0.1245, -0.3319, -0.0722],\n",
       "        [ 0.2302, -0.0884, -0.1089],\n",
       "        [ 0.0961,  0.0195,  0.0195]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protores_xyz_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "704918ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [-0.0643, -0.0033,  0.0291],\n",
       "        [-0.0162,  0.1818,  0.1205],\n",
       "        [-0.0658,  0.3751,  0.1050],\n",
       "        [ 0.0637,  0.0043, -0.0291],\n",
       "        [ 0.0521,  0.2088,  0.0199],\n",
       "        [ 0.0138,  0.4052,  0.0476],\n",
       "        [-0.0165, -0.1137, -0.0377],\n",
       "        [-0.0104, -0.2272, -0.0475],\n",
       "        [-0.0007, -0.2880, -0.0258],\n",
       "        [-0.0153, -0.3349, -0.0543],\n",
       "        [-0.0780, -0.1998, -0.0175],\n",
       "        [-0.1170, -0.0778,  0.0345],\n",
       "        [-0.1022,  0.0191,  0.0970],\n",
       "        [ 0.0532, -0.1934, -0.0734],\n",
       "        [ 0.1090, -0.0653, -0.0529],\n",
       "        [ 0.1409,  0.0374, -0.0040]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_xyz_17 - target_xyz_17[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93727ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 51])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['target_xyz_17'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0745894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_xyz_17.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03dfdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
